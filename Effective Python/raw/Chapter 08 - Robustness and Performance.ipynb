{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trying-kitty",
   "metadata": {},
   "source": [
    "## Item 65: Take Advantage of Each Block in `try`/`except`/`else`/`finally`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-custody",
   "metadata": {},
   "source": [
    "### `finally` Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-curve",
   "metadata": {},
   "source": [
    "- use `try/finally` when you want exceptions to propagate up but also want to run cleanup code even when exceptions occur\n",
    "- one common usage of `try`/`finally` is for reliably closing file handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "scheduled-feeling",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-1-0c3f2d5b473d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-0c3f2d5b473d>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    handle = open(filename, encoding='utf-8)\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def try_finally_example(filename):\n",
    "    print('* Opening file')\n",
    "    \n",
    "handle = open(filename, encoding='utf-8')\n",
    "try:\n",
    "    print('* Reading data')\n",
    "    return handle.read()\n",
    "finally:\n",
    "    print('* Calling close()')\n",
    "    handle.clode() # always run after try block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-civilian",
   "metadata": {},
   "source": [
    "### `else` Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-skiing",
   "metadata": {},
   "source": [
    "- use `try`/`else` to make it clear which excaptions will be handled by your code and which exceptions will propagate up\n",
    "- when the `try` block does not raise an exception, the `else` block runs\n",
    "- the `else` block helps you minimize the amount of code in the `try` block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specified-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_key(data, key):\n",
    "    try:\n",
    "        print('* Loading JSON data')\n",
    "        result_dict = json.loads(data) # May raise ValueError\n",
    "    except ValueError as e:\n",
    "        print('* Handling ValueError')\n",
    "        raise KeyError(key) from e\n",
    "    else:\n",
    "        print('* Looking up key')\n",
    "    return result_dict[key] # May raise KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-miller",
   "metadata": {},
   "source": [
    "- in the successful case, the JSON data is decoded in the `try` block and then the key lookup occurs in the `else` block\n",
    "- the `else` clause ensures that what follows the `try`/`except` is visually distinguished from the `except` block \n",
    "- this makes the exception proagation behavior clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-nicaragua",
   "metadata": {},
   "source": [
    "### Everything Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-quick",
   "metadata": {},
   "source": [
    "- use `try`/`except`/`finally` when you want to do it all in one compound statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-celebration",
   "metadata": {},
   "source": [
    "- the `try` block is used to read the file and process it\n",
    "- the `except` block is used to handle exceptions from the `try` block that are expected\n",
    "- the `else` block is used to update the file in place and allow related exception to proapagate up\n",
    "- the `finally` block cleans up the file handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convenient-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDEFINED = object()\n",
    "\n",
    "def divide_json(path):\n",
    "    print('* Opening file')\n",
    "    handle = open(path, 'r+') # May raise OSError\n",
    "    try:\n",
    "        print('* Reading data')\n",
    "        data = handle.read() # May raise UnicodeDecodeError\n",
    "        print('* Loading JSON data')\n",
    "        op = json.load(data) # May raise ValueError\n",
    "        print('* Performing calculation')\n",
    "        \n",
    "    except ZeroDivisionError as e:\n",
    "        print('* Handling ZeroDivisionError')\n",
    "        return UNDEFINED\n",
    "    else:\n",
    "        print('* Writing calculation')\n",
    "        op['result'] = value\n",
    "        result = json.dumps(op)\n",
    "        handle.seek(0)        # May raise OSError\n",
    "        handle.write(result)  # May raise OSError\n",
    "    finally:\n",
    "        print('* Calling close()')\n",
    "        handle.close()        # Always runs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-honor",
   "metadata": {},
   "source": [
    "## Item 66: Consider `contextlib` and `with` Statements for Reusable `try`/`finally` Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-investigator",
   "metadata": {},
   "source": [
    "- the `with` statement in Python is used to indicate when code is running in a special context\n",
    "- mutual-exclusion locks can be used in `with` statements to indicate that he indented code block runs only while the lock is held"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focal-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock\n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "with lock:\n",
    "    # Do something while maintaining an invariant\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-housing",
   "metadata": {},
   "source": [
    "- the example above is equivalent to this `try`/`finally` construction because the `Lock` class properly enables the `with` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "constant-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock.acquire()\n",
    "try:\n",
    "    # Do something while maintaining na invariant\n",
    "    pass\n",
    "finally:\n",
    "    lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-integral",
   "metadata": {},
   "source": [
    "- the `with` statement version of this is better because it eliminates the need to write the repetitive code of the `try`/`finally` construction and it ensures that you dont forget to have a corresponding `release` call for every acquire call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-arthur",
   "metadata": {},
   "source": [
    "- its easy to make your objects and functions work in `with` statements by using the `contextlib` built-in module\n",
    "- this module contains the `contextmanager` decorator which lets a simple function be used in `with` statements\n",
    "- this is much easier than defining a new class with the special methods `__enter__` and `__exit__`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-colorado",
   "metadata": {},
   "source": [
    "- for example, say I want a region of code to have more debug logging sometimes, we can define a function that does logging at two severity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ideal-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def my_function():\n",
    "    logging.debug('Some debug data')\n",
    "    logging.error('Error log here')\n",
    "    logging.debug('More debug data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-programmer",
   "metadata": {},
   "source": [
    "- the default log level for my program is `WARNING`, so only the error message will print to screen when I run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "protective-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error log here\n"
     ]
    }
   ],
   "source": [
    "my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-yukon",
   "metadata": {},
   "source": [
    "- we can elevate the log level of this function temporarily by defining a context manager\n",
    "- this helper function boosts the logging severity level before running the code in the `with` block and reduces the logging severity level afterward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "above-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def debug_logging(level):\n",
    "    logger = logging.getLogger()\n",
    "    old_level = logger.getEffectiveLevel()\n",
    "    logger.setLevel(level)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        logger.setLevel(old_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-white",
   "metadata": {},
   "source": [
    "- the `yield` expression is the point at which the `with` blocks context will execute\n",
    "- any exceptions that happen in the `with` block will be re-raised by the `yield` expression for you to catch in the helper function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-canon",
   "metadata": {},
   "source": [
    "- now we can call the same logging function again but in the `debug_logging context\n",
    "- this time, all of the debug messages are printed-to the screen during the `with` block\n",
    "- the same function running outside the with block wont print debug message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "heard-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:Some debug data\n",
      "ERROR:root:Error log here\n",
      "DEBUG:root:More debug data\n",
      "ERROR:root:Error log here\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Inside: \n",
      "* After: \n"
     ]
    }
   ],
   "source": [
    "with debug_logging(logging.DEBUG):\n",
    "    print('* Inside: ')\n",
    "    my_function()\n",
    "    \n",
    "print('* After: ')\n",
    "my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-nashville",
   "metadata": {},
   "source": [
    "## Using `with` Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-checklist",
   "metadata": {},
   "source": [
    "- the context manager passed to a `with` statement may also return an object\n",
    "- the object is assigned to a local variable in the `as` part of the compound statement\n",
    "- this gives the code running in the `with` block the ability to directly interact with ite context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-secretary",
   "metadata": {},
   "source": [
    "- for example, say we want to write to a file and ensure that its always closed correctly\n",
    "- we cand o this by passing `open` to the `with` statement\n",
    "- `open` returns a file handle for the `as` target of `with` and it colses the handle when the `with` block exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aggressive-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_output.txt', 'w') as handle:\n",
    "    handle.write('This is some data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-concord",
   "metadata": {},
   "source": [
    "- to enable your own function sto supply values for as targets, all you need to do is `yield` a value from your context manager\n",
    "- for example, below we define a context manager to fetch a `Logger` instance, set its level and then `yield` it a s the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "joined-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def log_level(level, name):\n",
    "    logger = logging.getLogger(name)\n",
    "    old_level = logger.getEffectiveLevel()\n",
    "    logger.setLevel(level)\n",
    "    try:\n",
    "        yield logger\n",
    "    finally:\n",
    "        logger.setLevel(old_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-steam",
   "metadata": {},
   "source": [
    "- calling logging methods like `debug` on the `as` target produces output because the logging severity level is set low enough in the `with` block on that specific `Logger` instance\n",
    "- using the `logging` module directly wont print anything because the default logging severity level for the default program logger is `WARNING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "missing-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:my-log:This is a message for my-log!\n",
      "DEBUG:my-log:This will not print\n"
     ]
    }
   ],
   "source": [
    "with log_level(logging.DEBUG, 'my-log') as logger:\n",
    "    logger.debug(f'This is a message for {logger.name}!')\n",
    "    logger.debug('This will not print')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-prairie",
   "metadata": {},
   "source": [
    "- after the `with` statement exits, calling debug logging methods on `Logger` named 'my-log' will not print anything because the default severity level has not been restored\n",
    "- error log messages will always print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "coupled-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:my-log:Error will print\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('my-log')\n",
    "logger.debug('Debug will not print')\n",
    "logger.error('Error will print')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-trailer",
   "metadata": {},
   "source": [
    "- later we can change the name of the logger we want to use by simply updating the `with` statement\n",
    "- this will point the `Logger` thats the `as` target in the `with` statement to a different instance, but we wont have to update any of my other code to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "utility-waste",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:other-log:This is a message for other-log!\n"
     ]
    }
   ],
   "source": [
    "with log_level(logging.DEBUG, 'other-log') as logger:\n",
    "    logger.debug(f'This is a message for {logger.name}!')\n",
    "    logging.debug('This will not print')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-monster",
   "metadata": {},
   "source": [
    "- the isolation of state and decoupling between creating a context and acting within the context is another benefit of the `with` statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-idaho",
   "metadata": {},
   "source": [
    "### Things to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-miniature",
   "metadata": {},
   "source": [
    "- the `with` statement allows you to reuse logic from `try/finally` blocks and reduce visual noise\n",
    "- the `contextlib` built-in module provides a `contextmanager` decorator that makes it easy to use your own functions in `with` statements\n",
    "- the value yeilded by context manager is supplied to the `as` part of the `with` statement\n",
    "- its useful for letting your code directly access the cause of a special context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-parallel",
   "metadata": {},
   "source": [
    "## Item 67: Use `datetime` Instead of `time` for Local Clocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-vacuum",
   "metadata": {},
   "source": [
    "- `datetime` built-in module works great with some hlep from the community package named `pytz`\n",
    "- we dont use `time` for its platform-dependent nature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-healing",
   "metadata": {},
   "source": [
    "- below is the code to convert the present time in `UTC` to my computer's local time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "classified-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 18:14:25-04:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "now = datetime(2019, 3, 16, 22, 14, 25)\n",
    "now_utc = now.replace(tzinfo=timezone.utc)\n",
    "now_local = now_utc.astimezone()\n",
    "print(now_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-cable",
   "metadata": {},
   "source": [
    "- the `datetime` module can also easily convert a local time back to a UNIX timestamp in UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "removable-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1552763675.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_str = '2019-03-16 15:14:35'\n",
    "time_format = '%Y-%m-%d %H:%M:%S'\n",
    "now = datetime.strptime(time_str, time_format)\n",
    "time_tuple = now.timetuple()\n",
    "utc_now = time.mktime(time_tuple)\n",
    "print(utc_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-complex",
   "metadata": {},
   "source": [
    "- `datetime` only provides time zone operations with its `tzinfo` class and related methods\n",
    "- the Python default installation is missing time zone definitions besides UTC\n",
    "- to avoid having to use the `tzinfo` class we can use the `pytz` module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-threshold",
   "metadata": {},
   "source": [
    "- to use `pytz` effectively, you should always convert local time to `UTC` first\n",
    "- perform any `datetime` operations you need on the `UTC` values\n",
    "- then convert to local times as a final step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-equality",
   "metadata": {},
   "source": [
    "- below we convert a NYC flight arrival time to a UTC `datetime`\n",
    "- although some of these calls seem redundant, all of them are necessary when using `pytz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "smaller-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 03:33:24+00:00\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "\n",
    "arrival_nyc = '2019-03-16 23:33:24'\n",
    "nyc_dt_naive = datetime.strptime(arrival_nyc, time_format)\n",
    "\n",
    "arrival_nyx = '2019-03-16 23:33:24'\n",
    "nyc_dt_naive = datetime.strptime(arrival_nyc, time_format)\n",
    "\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "nyc_dt = eastern.localize(nyc_dt_naive)\n",
    "utc_dt = pytz.utc.normalize(nyc_dt.astimezone(pytz.utc))\n",
    "print(utc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-bullet",
   "metadata": {},
   "source": [
    "- once we have a `UTC` datetime, we can convert it to `San Franciso` local time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "negative-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 20:33:24-07:00\n"
     ]
    }
   ],
   "source": [
    "pacific = pytz.timezone('US/Pacific')\n",
    "sf_dt = pacific.normalize(utc_dt.astimezone(pacific))\n",
    "print(sf_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-reminder",
   "metadata": {},
   "source": [
    "## Item 68: Make `pickle` Reliable with `copyreg`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-attachment",
   "metadata": {},
   "source": [
    "- `pickle` module can serialize python objects into a stream of bytes and deserialize bytes back into objects\n",
    "- say we want to use a Python object to represent the state of a players progress in a game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "municipal-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self):\n",
    "        self.level = 0\n",
    "        self.lives = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-hindu",
   "metadata": {},
   "source": [
    "- the program modifies this object as the game runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advised-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 1, 'lives': 3}\n"
     ]
    }
   ],
   "source": [
    "state = GameState()\n",
    "state.level += 1 # Player beat a level\n",
    "state.lives -= 1 # Player had to try again\n",
    "\n",
    "print(state.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-disposal",
   "metadata": {},
   "source": [
    "- when the user quits playing, the program can save the state of this game to a file so it can be resumed at a later time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-jersey",
   "metadata": {},
   "source": [
    "- we use `dump` function to write the `GameState` object to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "north-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "state_path = 'game_state.bin'\n",
    "with open(state_path, 'wb') as f:\n",
    "    pickle.dump(state, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-packaging",
   "metadata": {},
   "source": [
    "- later we can call the load function with the file and get back the `GameState` object as if it had never been serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "veterinary-subject",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 1, 'lives': 3}\n"
     ]
    }
   ],
   "source": [
    "with open(state_path, 'rb') as f:\n",
    "    state_after = pickle.load(f)\n",
    "    \n",
    "print(state_after.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-pioneer",
   "metadata": {},
   "source": [
    "- the problem with the approach is what happend as the game features expand over time\n",
    "- imagine you also wanted to track players point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "turkish-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self):\n",
    "        self.level = 0\n",
    "        self.lives = 4\n",
    "        self.point = 0 # New field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-montreal",
   "metadata": {},
   "source": [
    "- Serializing the new version of the `GameState` class using `pickle` will work exactly as before\n",
    "- we simulate the round-trip through a file by serializing to a string with `dumps` and back to an objec twith `loads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consolidated-penny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 0, 'lives': 4, 'point': 0}\n"
     ]
    }
   ],
   "source": [
    "state = GameState()\n",
    "serialized = pickle.dumps(state)\n",
    "state_after = pickle.loads(serialized)\n",
    "print(state_after.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-arkansas",
   "metadata": {},
   "source": [
    "- note that the older saved `GameState` object is not returned\n",
    "- we can unpickle an old game file by a program with the new definition of the `GameState` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chronic-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 1, 'lives': 3}\n"
     ]
    }
   ],
   "source": [
    "with open(state_path, 'rb') as f:\n",
    "    state_after = pickle.load(f)\n",
    "    \n",
    "print(state_after.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-suite",
   "metadata": {},
   "source": [
    "- the `points` attribute is missing\n",
    "- the behavior is a byproduct of the way the `pickle` module works\n",
    "- its primary use case is making object serialization easy\n",
    "- as soon as your use of `pickle` moves beyond trivial usage, the module's functionality starts to break down in surprising way\n",
    "- fixing these problems is straightforward using the `copyreg` built-in module\n",
    "- the `copyreg` module lets you register the functions resposibility for serializing and deserializing Python objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-vertex",
   "metadata": {},
   "source": [
    "### Default Attribute Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-southeast",
   "metadata": {},
   "source": [
    "- in the simplest case, you can use a constructor with default arguments to ensure that `GameState` objects will always have all attributes after unpickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "damaged-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, level=0, lives=4, points=0):\n",
    "        self.level = level\n",
    "        self.lives = lives\n",
    "        self.points = points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-rugby",
   "metadata": {},
   "source": [
    "- to use this constructor for pickling, we define a helper function that takes a `GameState` object and turnes it into a `tuple` of parameters for the `copyreg` module\n",
    "- the returned `tuple` contains the function to use for unpickling and the parameters to pass the unpickling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fourth-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_game_state(game_state):\n",
    "    kwargs = game_state.__dict__\n",
    "    return unpickle_game_state, (kwargs, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-brown",
   "metadata": {},
   "source": [
    "- now we need to define the `unpickle_game_state` helper\n",
    "- this function takes serialized data and parameters from `pickle_game_state` and returns the corresponding `GameState` object\n",
    "- its a tiny wrapper around the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pacific-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle_game_state(kwargs):\n",
    "    return GameState(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-plaintiff",
   "metadata": {},
   "source": [
    "- we register these functions with the `copyreg` built-in module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worldwide-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copyreg\n",
    "\n",
    "copyreg.pickle(GameState, pickle_game_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-malawi",
   "metadata": {},
   "source": [
    "- after registration, serializing and deserializing works as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "finite-timothy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 0, 'lives': 4, 'points': 1000}\n"
     ]
    }
   ],
   "source": [
    "state = GameState()\n",
    "state.points += 1000\n",
    "serialized = pickle.dumps(state)\n",
    "state_after = pickle.loads(serialized)\n",
    "print(state_after.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-thanksgiving",
   "metadata": {},
   "source": [
    "- we can now change the definition of `GameState` again and give players a count of magic spells to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "behavioral-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, level=0, lives=4, points=0, magic=5):\n",
    "        self.level = level\n",
    "        self.lives = lives\n",
    "        self.points = points\n",
    "        self.magic = magic # New field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-subscription",
   "metadata": {},
   "source": [
    "- unlike before, deserializing an old `GameState` object will result in valid game data instead of missing attributes\n",
    "- this works because `unpickle_game_state` calls the `GameState` constructor directly instead of using the `pickle` modules default behavior of saving and restoring onl the attributes that belong to an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "incredible-taylor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: {'level': 0, 'lives': 4, 'points': 1000}\n",
      "After:  {'level': 0, 'lives': 4, 'points': 1000, 'magic': 5}\n"
     ]
    }
   ],
   "source": [
    "print('Before:', state.__dict__)\n",
    "state_after = pickle.loads(serialized)\n",
    "print('After: ', state_after.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-boundary",
   "metadata": {},
   "source": [
    "### Versioning Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-console",
   "metadata": {},
   "source": [
    "- sometimes you need to make backward-incompatible changes to your Python objects by removing fields\n",
    "- doing this prevents the default argument approach above from working\n",
    "- say we remove the number of lives from the `GameState`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "attractive-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, level=0, points=0, magic=5):\n",
    "        self.level = level\n",
    "        self.points = points\n",
    "        self.magic = magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-screen",
   "metadata": {},
   "source": [
    "- the problem is that this breaks deserialization of old game data\n",
    "- all fields from the old data, even ones removed from the class will be passed to the `GameState` constructor by the `unpickle_game_state` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "standard-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following causes TypeError\n",
    "# pickle.loads(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-bandwidth",
   "metadata": {},
   "source": [
    "- we can fix this by adding new version parameters to the function supplied to `copyreg`\n",
    "- now serialized data will have a version of 2 specified when pickling a new `GameState` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "manual-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_game_state(game_state):\n",
    "    kwargs = game_state.__dict__\n",
    "    kwargs['version'] = 2\n",
    "    return unpickle_game_state, (kwargs, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-franchise",
   "metadata": {},
   "source": [
    "- old versions of the data will noe have a `version` argument present\n",
    "- this means we can manipulate the arguments passed to the `GameState` constructor accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "split-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle_game_state(kwargs):\n",
    "    version = kwargs.pop('version', 1)\n",
    "    if version == 1:\n",
    "        del kwargs['lives']\n",
    "    return GameState(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-portugal",
   "metadata": {},
   "source": [
    "- now deserializing an old object works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sustained-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  {'level': 0, 'lives': 4, 'points': 1000}\n",
      "After:  {'level': 0, 'points': 1000, 'magic': 5}\n"
     ]
    }
   ],
   "source": [
    "copyreg.pickle(GameState, pickle_game_state)\n",
    "print('Before: ', state.__dict__)\n",
    "state_after = pickle.loads(serialized)\n",
    "print('After: ', state_after.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-hepatitis",
   "metadata": {},
   "source": [
    "- anytime we need to adapt old versions of the same class, we can go the `unpickle_game_state` function and change the `version`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-phone",
   "metadata": {},
   "source": [
    "### Stable Import Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-athens",
   "metadata": {},
   "source": [
    "- other isssues with `pickle` could be breakage from renaming a class\n",
    "- often over the lifecycle of a program, you'll refactor your code by renaming classes and moving them to other modules\n",
    "- doing so breakes the `pickle` module unless your careful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-eclipse",
   "metadata": {},
   "source": [
    "- below we rename the `GameState` class and remove the old class from the program entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "capable-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterGameState:\n",
    "    def __init__(self, level=0, points=0, magic=5):\n",
    "        self.level = level\n",
    "        self.points = points\n",
    "        self.magic = magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-toilet",
   "metadata": {},
   "source": [
    "- attempting to deserialize an old `GameState`object fails because the class cant be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "checked-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GameState at 0x2004a652310>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lol we should be getting an error here?\n",
    "pickle.loads(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-street",
   "metadata": {},
   "source": [
    "- the cause of the exception is that the import path of the serialized objects class is encoded in the pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "satisfactory-samoa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95L\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main__\\x94\\x8c\\x13unpickle_game_state\\x94\\x93\\x94}\\x94(\\x8c\\x05level\\x94K\\x00\\x8c\\x05lives\\x94K\\x04\\x8c\\x06points\\x94M\\xe8\\x03u\\x85\\x94R\\x94.'\n"
     ]
    }
   ],
   "source": [
    "print(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-accommodation",
   "metadata": {},
   "source": [
    "- the solution is to use `copyreg` again\n",
    "- we can specify a stable identifier for the function to use for unpickling an object\n",
    "- this allows us to transition pickled data to a different classes with different names when its deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "historical-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "copyreg.pickle(BetterGameState, pickle_game_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-parent",
   "metadata": {},
   "source": [
    "- after we use `copyreg` you can see that the import path to `unpickled_game_state` is encoded int hat serialized data instead of `BetterGameState`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "weighted-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\x80\\x04\\x95Y\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main__\\x94\\x8c\\x13unpickle_game_state\\x94\\x93\\x94}\\x94(\\x8c\\x05level\\x94K\\x00\\x8c\\x06points\\x94K\\x00\\x8c\\x05magic\\x94K\\x05\\x8c\\x07version\\x94K\\x02uK\\x02\\x86\\x94R\\x94.'\n"
     ]
    }
   ],
   "source": [
    "state = BetterGameState()\n",
    "serialized = pickle.dumps(state)\n",
    "print(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-finland",
   "metadata": {},
   "source": [
    "- remember you cant change the path of the module in which the `unpickle_game_state` function is present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-replacement",
   "metadata": {},
   "source": [
    "## Item   69: Use `decimal` When Precision is Paramount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-dressing",
   "metadata": {},
   "source": [
    "- if you need a precise number with a eplision of `0.0001`, you could use the `round` function but due to floating point error, rounding to the nearest whole cent could reduce the final cost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-stream",
   "metadata": {},
   "source": [
    "- solution is to use the `Decimal` class from the `decimal` built-in module\n",
    "- the `Decimal` class provides fixed point math of 28 decimal places by default; it can go even higher, if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "stopped-trance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.365\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "rate = Decimal('1.45')\n",
    "seconds = Decimal(3*60 + 42)\n",
    "cost = rate * seconds / Decimal(60)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-motivation",
   "metadata": {},
   "source": [
    "- `Decimal` instances can be given starting values in two different ways\n",
    "- the first is by passing `str` containing the number to the `Decimal` constructor\n",
    "- this ensures that there is no loss of precision\n",
    "- the second way is by directly passing a `float` or an `int` instance to the constructor\n",
    "- perfer `str` over exact value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sudden-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45\n",
      "1.4499999999999999555910790149937383830547332763671875\n"
     ]
    }
   ],
   "source": [
    "print(Decimal('1.45'))\n",
    "print(Decimal(1.45))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-variety",
   "metadata": {},
   "source": [
    "- lets suppose we ant to support short phone calls between places that are cheap\n",
    "- we can compute the charge for a phone call that was `5` seconds long with a rate of `0.05/min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "french-infection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004166666666666666666666666667\n"
     ]
    }
   ],
   "source": [
    "rate = Decimal('0.05')\n",
    "seconds = Decimal('5')\n",
    "small_cost = rate * seconds / Decimal(60)\n",
    "print(small_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-humidity",
   "metadata": {},
   "source": [
    "- the result is so low that it is decreased to zero when we try to round ti to the nearest whole cent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "blessed-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00\n"
     ]
    }
   ],
   "source": [
    "print(round(small_cost, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-astronomy",
   "metadata": {},
   "source": [
    "- the `Decimal` class has a built-in function for rounding to exactly the decimal palce needed with the desired rounding behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "personalized-nutrition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded 5.365 to 5.37\n"
     ]
    }
   ],
   "source": [
    "from decimal import ROUND_UP\n",
    "\n",
    "rounded = cost.quantize(Decimal('0.01'), rounding=ROUND_UP)\n",
    "print(f'Rounded {cost} to {rounded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-import",
   "metadata": {},
   "source": [
    "- using the `quantize` method this way also properly handles the small usage case for `short` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "tired-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded 0.004166666666666666666666666667 to 0.01\n"
     ]
    }
   ],
   "source": [
    "rounded = small_cost.quantize(Decimal('0.01'), \n",
    "                              rounding=ROUND_UP)\n",
    "\n",
    "print(f'Rounded {small_cost} to {rounded}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-disclaimer",
   "metadata": {},
   "source": [
    "- for representing rational numbers with no limit to precision, consider using the `Fraction` class from the `fractions` built-in module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-correction",
   "metadata": {},
   "source": [
    "## Item 70: Profile Before Optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-accordance",
   "metadata": {},
   "source": [
    "- dynamic nature of Python causes surprising behaviors in its runtime performance\n",
    "- operations you might assume would be slow are fast\n",
    "    - string manipulation, generators, etc.\n",
    "- operations that you would assume would be fast are actually slow\n",
    "    - attribute accesses, fucntion calls, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-weekend",
   "metadata": {},
   "source": [
    "- Python provides a built-in `profiler` for determining which parts of a program are responsible for its execution time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-lightning",
   "metadata": {},
   "source": [
    "- the `cProfile` is better than the `profile` because of its minimal impact on the performance of your program while its being profiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-marketing",
   "metadata": {},
   "source": [
    "> be sure that what you're measuring is the code itself and not external systems. Beware of functions that access the network or resources on disk. These may appear to have large impact on your programs exectuion time because of the slowness of the underlying systems.  If your program uses a cache to make the latency of slow resources like these, you should ensure that its properly warmed up before you start profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-quebec",
   "metadata": {},
   "source": [
    "- say I want to determine why an algorithm is low\n",
    "- we can define a function that sorts a `list` of data using an insertion sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "capable-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        insert_value(result, value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-richmond",
   "metadata": {},
   "source": [
    "- the core mechanism of the insertion sort is the function that finds the insertion point for each peice of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "accessory-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_value(array, value):\n",
    "    for i, existing in enumerate(array):\n",
    "        if existing > value:\n",
    "            array.insert(i, value)\n",
    "            return\n",
    "    array.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-conditioning",
   "metadata": {},
   "source": [
    "- to profile `insertion_sort` and `insert_value`, we create a data set of random number and define a `test` function to pass to the profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "needed-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "max_size = 10**4\n",
    "data = [randint(0, max_size) for _ in range(max_size)]\n",
    "test = lambda: insertion_sort(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-medium",
   "metadata": {},
   "source": [
    "- here we instantiate a `Profile` object from the `cProfile` module and run the test function through it using the `runcall` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fixed-looking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 25,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 39,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 44,\n",
       " 48,\n",
       " 48,\n",
       " 50,\n",
       " 50,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 55,\n",
       " 56,\n",
       " 62,\n",
       " 63,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 68,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 73,\n",
       " 73,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 77,\n",
       " 78,\n",
       " 78,\n",
       " 78,\n",
       " 78,\n",
       " 78,\n",
       " 81,\n",
       " 82,\n",
       " 85,\n",
       " 86,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 95,\n",
       " 95,\n",
       " 96,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 102,\n",
       " 103,\n",
       " 103,\n",
       " 104,\n",
       " 104,\n",
       " 104,\n",
       " 105,\n",
       " 105,\n",
       " 107,\n",
       " 109,\n",
       " 110,\n",
       " 110,\n",
       " 111,\n",
       " 111,\n",
       " 111,\n",
       " 112,\n",
       " 114,\n",
       " 115,\n",
       " 115,\n",
       " 115,\n",
       " 117,\n",
       " 118,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 126,\n",
       " 126,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 129,\n",
       " 132,\n",
       " 135,\n",
       " 135,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 136,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 139,\n",
       " 141,\n",
       " 143,\n",
       " 147,\n",
       " 147,\n",
       " 147,\n",
       " 149,\n",
       " 149,\n",
       " 149,\n",
       " 149,\n",
       " 152,\n",
       " 154,\n",
       " 155,\n",
       " 157,\n",
       " 157,\n",
       " 157,\n",
       " 158,\n",
       " 158,\n",
       " 158,\n",
       " 159,\n",
       " 161,\n",
       " 161,\n",
       " 162,\n",
       " 162,\n",
       " 163,\n",
       " 166,\n",
       " 167,\n",
       " 170,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 172,\n",
       " 172,\n",
       " 177,\n",
       " 179,\n",
       " 179,\n",
       " 179,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 180,\n",
       " 183,\n",
       " 186,\n",
       " 188,\n",
       " 191,\n",
       " 191,\n",
       " 193,\n",
       " 194,\n",
       " 196,\n",
       " 197,\n",
       " 197,\n",
       " 199,\n",
       " 199,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 201,\n",
       " 203,\n",
       " 203,\n",
       " 205,\n",
       " 205,\n",
       " 206,\n",
       " 206,\n",
       " 207,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 214,\n",
       " 214,\n",
       " 217,\n",
       " 219,\n",
       " 219,\n",
       " 219,\n",
       " 222,\n",
       " 225,\n",
       " 225,\n",
       " 226,\n",
       " 228,\n",
       " 228,\n",
       " 228,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 230,\n",
       " 230,\n",
       " 230,\n",
       " 233,\n",
       " 235,\n",
       " 235,\n",
       " 236,\n",
       " 238,\n",
       " 240,\n",
       " 240,\n",
       " 241,\n",
       " 241,\n",
       " 242,\n",
       " 242,\n",
       " 243,\n",
       " 243,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 245,\n",
       " 245,\n",
       " 246,\n",
       " 248,\n",
       " 250,\n",
       " 251,\n",
       " 253,\n",
       " 253,\n",
       " 253,\n",
       " 254,\n",
       " 254,\n",
       " 256,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 261,\n",
       " 261,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 263,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 268,\n",
       " 269,\n",
       " 269,\n",
       " 274,\n",
       " 275,\n",
       " 275,\n",
       " 276,\n",
       " 276,\n",
       " 276,\n",
       " 277,\n",
       " 281,\n",
       " 281,\n",
       " 281,\n",
       " 282,\n",
       " 284,\n",
       " 284,\n",
       " 285,\n",
       " 287,\n",
       " 287,\n",
       " 290,\n",
       " 290,\n",
       " 291,\n",
       " 293,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 296,\n",
       " 299,\n",
       " 300,\n",
       " 302,\n",
       " 302,\n",
       " 307,\n",
       " 307,\n",
       " 307,\n",
       " 308,\n",
       " 310,\n",
       " 311,\n",
       " 311,\n",
       " 312,\n",
       " 312,\n",
       " 314,\n",
       " 314,\n",
       " 315,\n",
       " 317,\n",
       " 317,\n",
       " 317,\n",
       " 319,\n",
       " 319,\n",
       " 320,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 322,\n",
       " 326,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 330,\n",
       " 331,\n",
       " 331,\n",
       " 331,\n",
       " 331,\n",
       " 331,\n",
       " 333,\n",
       " 333,\n",
       " 336,\n",
       " 336,\n",
       " 336,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 343,\n",
       " 343,\n",
       " 347,\n",
       " 347,\n",
       " 350,\n",
       " 350,\n",
       " 351,\n",
       " 351,\n",
       " 351,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 356,\n",
       " 359,\n",
       " 360,\n",
       " 360,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 364,\n",
       " 365,\n",
       " 365,\n",
       " 366,\n",
       " 366,\n",
       " 368,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 372,\n",
       " 373,\n",
       " 373,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 377,\n",
       " 378,\n",
       " 378,\n",
       " 378,\n",
       " 379,\n",
       " 379,\n",
       " 379,\n",
       " 381,\n",
       " 381,\n",
       " 382,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 387,\n",
       " 391,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 394,\n",
       " 394,\n",
       " 395,\n",
       " 395,\n",
       " 397,\n",
       " 397,\n",
       " 398,\n",
       " 400,\n",
       " 403,\n",
       " 405,\n",
       " 407,\n",
       " 409,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 411,\n",
       " 414,\n",
       " 415,\n",
       " 418,\n",
       " 420,\n",
       " 423,\n",
       " 425,\n",
       " 427,\n",
       " 428,\n",
       " 430,\n",
       " 432,\n",
       " 432,\n",
       " 434,\n",
       " 435,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 438,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 442,\n",
       " 443,\n",
       " 443,\n",
       " 444,\n",
       " 446,\n",
       " 446,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 450,\n",
       " 450,\n",
       " 452,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 454,\n",
       " 456,\n",
       " 457,\n",
       " 457,\n",
       " 458,\n",
       " 460,\n",
       " 460,\n",
       " 463,\n",
       " 463,\n",
       " 464,\n",
       " 466,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 471,\n",
       " 472,\n",
       " 472,\n",
       " 473,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 483,\n",
       " 483,\n",
       " 483,\n",
       " 484,\n",
       " 484,\n",
       " 485,\n",
       " 485,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 493,\n",
       " 495,\n",
       " 495,\n",
       " 498,\n",
       " 499,\n",
       " 503,\n",
       " 503,\n",
       " 505,\n",
       " 505,\n",
       " 506,\n",
       " 506,\n",
       " 506,\n",
       " 507,\n",
       " 507,\n",
       " 508,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 513,\n",
       " 513,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 518,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 521,\n",
       " 523,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 525,\n",
       " 525,\n",
       " 526,\n",
       " 526,\n",
       " 528,\n",
       " 530,\n",
       " 532,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 539,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 548,\n",
       " 549,\n",
       " 552,\n",
       " 552,\n",
       " 553,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 558,\n",
       " 559,\n",
       " 559,\n",
       " 560,\n",
       " 560,\n",
       " 562,\n",
       " 562,\n",
       " 562,\n",
       " 563,\n",
       " 563,\n",
       " 563,\n",
       " 563,\n",
       " 564,\n",
       " 566,\n",
       " 567,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 569,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 579,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 588,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 592,\n",
       " 594,\n",
       " 594,\n",
       " 595,\n",
       " 598,\n",
       " 598,\n",
       " 601,\n",
       " 602,\n",
       " 602,\n",
       " 604,\n",
       " 605,\n",
       " 605,\n",
       " 609,\n",
       " 609,\n",
       " 609,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 613,\n",
       " 614,\n",
       " 614,\n",
       " 616,\n",
       " 617,\n",
       " 620,\n",
       " 621,\n",
       " 621,\n",
       " 622,\n",
       " 622,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 624,\n",
       " 625,\n",
       " 627,\n",
       " 628,\n",
       " 628,\n",
       " 629,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 631,\n",
       " 632,\n",
       " 634,\n",
       " 635,\n",
       " 635,\n",
       " 637,\n",
       " 639,\n",
       " 640,\n",
       " 640,\n",
       " 642,\n",
       " 642,\n",
       " 642,\n",
       " 643,\n",
       " 643,\n",
       " 644,\n",
       " 644,\n",
       " 645,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 650,\n",
       " 651,\n",
       " 651,\n",
       " 653,\n",
       " 654,\n",
       " 654,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 660,\n",
       " 661,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 664,\n",
       " 664,\n",
       " 665,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 668,\n",
       " 669,\n",
       " 669,\n",
       " 670,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 676,\n",
       " 676,\n",
       " 677,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 679,\n",
       " 680,\n",
       " 683,\n",
       " 686,\n",
       " 686,\n",
       " 689,\n",
       " 689,\n",
       " 689,\n",
       " 690,\n",
       " 692,\n",
       " 692,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 694,\n",
       " 695,\n",
       " 697,\n",
       " 698,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 701,\n",
       " 704,\n",
       " 704,\n",
       " 704,\n",
       " 704,\n",
       " 705,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 710,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 714,\n",
       " 717,\n",
       " 717,\n",
       " 718,\n",
       " 722,\n",
       " 723,\n",
       " 723,\n",
       " 725,\n",
       " 725,\n",
       " 727,\n",
       " 727,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 729,\n",
       " 729,\n",
       " 730,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 735,\n",
       " 735,\n",
       " 735,\n",
       " 738,\n",
       " 738,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 740,\n",
       " 740,\n",
       " 742,\n",
       " 743,\n",
       " 745,\n",
       " 746,\n",
       " 750,\n",
       " 751,\n",
       " 753,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 758,\n",
       " 758,\n",
       " 760,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 766,\n",
       " 768,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 772,\n",
       " 772,\n",
       " 773,\n",
       " 775,\n",
       " 777,\n",
       " 777,\n",
       " 778,\n",
       " 778,\n",
       " 779,\n",
       " 779,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 787,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 794,\n",
       " 794,\n",
       " 796,\n",
       " 797,\n",
       " 797,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 801,\n",
       " 801,\n",
       " 802,\n",
       " 802,\n",
       " 806,\n",
       " 807,\n",
       " 807,\n",
       " 808,\n",
       " 810,\n",
       " 811,\n",
       " 813,\n",
       " 816,\n",
       " 817,\n",
       " 817,\n",
       " 817,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 821,\n",
       " 822,\n",
       " 822,\n",
       " 823,\n",
       " 823,\n",
       " 823,\n",
       " 824,\n",
       " 824,\n",
       " 824,\n",
       " 824,\n",
       " 824,\n",
       " 825,\n",
       " 825,\n",
       " 825,\n",
       " 826,\n",
       " 828,\n",
       " 828,\n",
       " 830,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 835,\n",
       " 836,\n",
       " 841,\n",
       " 842,\n",
       " 846,\n",
       " 846,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 849,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 851,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 868,\n",
       " 869,\n",
       " 869,\n",
       " 869,\n",
       " 872,\n",
       " 872,\n",
       " 873,\n",
       " 873,\n",
       " 874,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 880,\n",
       " 880,\n",
       " 880,\n",
       " 881,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 884,\n",
       " 884,\n",
       " 885,\n",
       " 885,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 887,\n",
       " 888,\n",
       " 891,\n",
       " 893,\n",
       " 897,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 904,\n",
       " 905,\n",
       " 905,\n",
       " 906,\n",
       " 906,\n",
       " 908,\n",
       " 908,\n",
       " 909,\n",
       " 911,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 922,\n",
       " 926,\n",
       " 926,\n",
       " 928,\n",
       " 929,\n",
       " 931,\n",
       " 931,\n",
       " 931,\n",
       " 935,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 939,\n",
       " 943,\n",
       " 943,\n",
       " 944,\n",
       " 944,\n",
       " 944,\n",
       " 945,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 951,\n",
       " 952,\n",
       " 954,\n",
       " 955,\n",
       " 957,\n",
       " 958,\n",
       " 958,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 966,\n",
       " 966,\n",
       " 970,\n",
       " 970,\n",
       " 970,\n",
       " 971,\n",
       " 971,\n",
       " 973,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 978,\n",
       " 979,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 981,\n",
       " 981,\n",
       " 982,\n",
       " 984,\n",
       " 987,\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cProfile import Profile\n",
    "\n",
    "profiler = Profile()\n",
    "profiler.runcall(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-variety",
   "metadata": {},
   "source": [
    "- when the test function has finished running, we can extract statistics about its performance by using the `pstat` module and its `Stats` class\n",
    "- various methods on a `Stats` object adjust how to select and sort the `profiling` information to show only the things I case about "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "broad-liability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         20003 function calls in 1.845 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    1.845    1.845 <ipython-input-64-2fd13660a10c>:4(<lambda>)\n",
      "        1    0.005    0.005    1.845    1.845 <ipython-input-61-cbe174de868f>:1(insertion_sort)\n",
      "    10000    1.820    0.000    1.840    0.000 <ipython-input-63-c4fc1ad100fb>:1(insert_value)\n",
      "     9990    0.019    0.000    0.019    0.000 {method 'insert' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x2004a60eee0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pstats import Stats\n",
    "\n",
    "stats = Stats(profiler)\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-symposium",
   "metadata": {},
   "source": [
    "- `ncalls`: the number of calls to the function during the profiling\n",
    "- `tottime`: the number of seconds spent executing the function exlcuding time spent executing other function calls\n",
    "- `tottime percall`: the average number of seconds spent executing the function excluding time spent executing other functions it calls; this is `tottime` divided by `ncalls`\n",
    "- `cumtime`: the cumulative number of seconds spent executing the function, including time spent in all other functions it calls\n",
    "- `cumtime percall`the average number of seconds spent in the function call each time its called, including time spent in all other functions each time it is called; this is `cumtime` divided by `ncalls`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-plant",
   "metadata": {},
   "source": [
    "- you can also call `stats.print_callers()` to show what is being called"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-provincial",
   "metadata": {},
   "source": [
    "## Item 71: Perfer `deque` for Producer_consumer Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-friendship",
   "metadata": {},
   "source": [
    "- imagine we have a program that processing incomming emails for long-term archival, and its using a `list` for producer-consuming queue\n",
    "- we define a class represent the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accepted-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Email:\n",
    "    def __init__(self, sender, receiver, message):\n",
    "        self.sender = sender\n",
    "        self.receiver = receiver\n",
    "        self.message = message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-relation",
   "metadata": {},
   "source": [
    "- we define a placeholder function for receiving a single email, presumably from a socket, the file system or some other type of `I/O` system\n",
    "- the implementation of this function does not matte, whats important is the interface: it either returns an `Email` instance or raise a `NoEmailError` exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "drawn-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoEmailError(Exception):\n",
    "    pass\n",
    "\n",
    "def try_receive_email():\n",
    "    # Returns an Email instance or raises NoEmailError\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-former",
   "metadata": {},
   "source": [
    "- the producing function receives emails and enqueues them to be consumed at a later time\n",
    "- the function uses the `append` method on the `list` to add new messages to the end of the queue so they are processed after all messages that were previously received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polar-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_emails(queue):\n",
    "    while True:\n",
    "        try:\n",
    "            email = try_receive_email()\n",
    "        except NoEmailError:\n",
    "            return\n",
    "        else:\n",
    "            queue.append(email) # Producer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-mustang",
   "metadata": {},
   "source": [
    "- the consuming function does something useful with the emails\n",
    "- the function calls `pop(0)` on the queue, which removes the very first time from the `list` and returns it to the caller\n",
    "- this perserves the order in which emails were received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floating-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_one_email(queue):\n",
    "    if not queue:\n",
    "        return\n",
    "    email = queue.pop(0) # Consumer\n",
    "    \n",
    "    # Index the message for long-term archival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-disco",
   "metadata": {},
   "source": [
    "- finally we need a looping function that conenctgs the pieces together\n",
    "- this function alternates between producing and consuming unitl the `keep_running` functions returns `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "secondary-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(queue, keep_running):\n",
    "    while keep_running():\n",
    "        produce_emails(queue)\n",
    "        consume_one_email(queue)\n",
    "        \n",
    "def my_end_func():\n",
    "    pass\n",
    "\n",
    "loop([], my_end_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-astronomy",
   "metadata": {},
   "source": [
    "- the reson we do not process each `Email` message in `produce_emails` as it's returned by `try_receive_email` is because of the trade-off between latency and throughput\n",
    "- when using producer-consumer queues, you want to minimize the latency of accpeting new items so they can be collected as fast as possible\n",
    "- the consumer can then process through the backlog og items at a consistent pace- one item per loop\n",
    "- this provides a stable performance profile and consistent throughput at the cost of end-to-end latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-coalition",
   "metadata": {},
   "source": [
    "- using a `list` for a producer-consumer queue like this works fine up to a point, but as the `cardinality`- the number of items in the list increases, the `list` type's performance can degrade superlineraly\n",
    "- if we `micro-benchmark` using the `timeit` module we can analyze the performance\n",
    "- we define a benchmark for the performance of adding new items to the queue using the `append` method of `list` (matching the producer function's usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "linear-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def print_results(count, tests):\n",
    "    avg_iteration = sum(tests) / len(tests)\n",
    "    print(f'Count {count:>5,} takes {avg_iteration:.6f}s')\n",
    "    return count, avg_iteration\n",
    "\n",
    "def list_append_benchmark(count):\n",
    "    def run(queue):\n",
    "        for i in range(count):\n",
    "            queue.append(i)\n",
    "        \n",
    "    tests = timeit.repeat(\n",
    "        setup='queue = []',\n",
    "        stmt='run(queue)',\n",
    "        globals=locals(),\n",
    "        repeat=1000,\n",
    "        number=1)\n",
    "    return print_results(count, tests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-seeker",
   "metadata": {},
   "source": [
    "- running this benchmark function with different levels of cardinality lets us compare its performance in relationship to data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "manufactured-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count   500 takes 0.000063s\n",
      "Count 1,000 takes 0.000108s\n",
      " 2.0x data size,  1.7x time\n",
      "Count 2,000 takes 0.000167s\n",
      " 4.0x data size,  2.6x time\n",
      "Count 3,000 takes 0.000229s\n",
      " 6.0x data size,  3.6x time\n",
      "Count 4,000 takes 0.000320s\n",
      " 8.0x data size,  5.1x time\n",
      "Count 5,000 takes 0.000402s\n",
      "10.0x data size,  6.4x time\n"
     ]
    }
   ],
   "source": [
    "def print_delta(before, after):\n",
    "    before_count, before_time = before\n",
    "    after_count, after_time = after\n",
    "    growth = 1 + (after_count - before_count) / before_count\n",
    "    slowdown = 1 + (after_time - before_time) / before_time\n",
    "    print(f'{growth:>4.1f}x data size, {slowdown:>4.1f}x time')\n",
    "    \n",
    "baseline = list_append_benchmark(500)\n",
    "for count in (1_000, 2_000, 3_000, 4_000, 5_000):\n",
    "    comparison = list_append_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-harassment",
   "metadata": {},
   "source": [
    "- this shows that the `append` method takes roughly constant time for the `list` type and the total time for enqueueing scales linearly as the data size increases\n",
    "- there is overhead for the `list` type to increase its capacity under the covers as new items are added, but its reaonably low and is amortized across repeated calls to `append`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-effect",
   "metadata": {},
   "source": [
    "- below we define a similar benchmark for the `pop(0)` call that removes items from the beginning of the queue (matching the consumer function's usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "filled-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_pop_benchmark(count):\n",
    "    def prepare():\n",
    "        return list(range(count))\n",
    "    \n",
    "    def run(queue):\n",
    "        while queue:\n",
    "            queue.pop(0)\n",
    "    \n",
    "    tests = timeit.repeat(\n",
    "        setup='queue = prepare()',\n",
    "        stmt='run(queue)',\n",
    "        globals=locals(),\n",
    "        repeat=1000,\n",
    "        number=1)\n",
    "    \n",
    "    return print_results(count, tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-oxide",
   "metadata": {},
   "source": [
    "- we can similarly run this benchmark for queues of different sizes to see how performance is affected by cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "smart-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count   500 takes 0.000112s\n",
      "Count 1,000 takes 0.000233s\n",
      " 2.0x data size,  2.1x time\n",
      "Count 2,000 takes 0.000734s\n",
      " 4.0x data size,  6.5x time\n",
      "Count 3,000 takes 0.001450s\n",
      " 6.0x data size, 12.9x time\n",
      "Count 4,000 takes 0.002731s\n",
      " 8.0x data size, 24.3x time\n",
      "Count 5,000 takes 0.004136s\n",
      "10.0x data size, 36.8x time\n"
     ]
    }
   ],
   "source": [
    "baseline = list_pop_benchmark(500)\n",
    "for count in (1_000, 2_000, 3_000, 4_000, 5_000):\n",
    "    comparison = list_pop_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-theory",
   "metadata": {},
   "source": [
    "- this shows that the total time for dequeuing items from a `list` with `pop(0)` scales quadratically as the lenght of the queue increases\n",
    "- the causes is that `pop(0)` needs to move every item in the `list` back an index, effectively ressagning the entire list's contents\n",
    "- we need to call `pop(0)` for every item in the `list` and thus I end up doing roughly `len(queue) * len(queue)` operations to consume the queue; this does not scale \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-egyptian",
   "metadata": {},
   "source": [
    "- python provides the `deque` class from the collections module\n",
    "- `deque` is a double-ended queue implementation\n",
    "- it provides constant time operations for insetrting or removing items from it beginning or end\n",
    "- this makes it ideal for `FIFO` queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-deadline",
   "metadata": {},
   "source": [
    "- to use the `deque` class, we call to `append` in `produce_emails` can stay the same as it was when using a `list` for queue\n",
    "- the `list.pop` method call in `consume_one_email` must change to call the `deque.popleft` method with no arguments instead of a `list`\n",
    "- we redifine the one function affected to use the new method and run `loop` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "complex-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def consume_one_email(queue):\n",
    "    if not queue:\n",
    "        return\n",
    "    email = queue.popleft() # Consumer\n",
    "    # Process the email message\n",
    "    \n",
    "def my_end_func():\n",
    "    pass\n",
    "\n",
    "loop(collections.deque(), my_end_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-transformation",
   "metadata": {},
   "source": [
    "- we can run another version of the benchmark to verify that `append` perfromance has stayed roughly the same (module a constant factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cathedral-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count   500 takes 0.000052s\n",
      "Count 1,000 takes 0.000102s\n",
      " 2.0x data size,  2.0x time\n",
      "Count 2,000 takes 0.000155s\n",
      " 4.0x data size,  3.0x time\n",
      "Count 3,000 takes 0.000254s\n",
      " 6.0x data size,  4.9x time\n",
      "Count 4,000 takes 0.000331s\n",
      " 8.0x data size,  6.3x time\n",
      "Count 5,000 takes 0.000383s\n",
      "10.0x data size,  7.3x time\n"
     ]
    }
   ],
   "source": [
    "def deque_append_benchmark(count):\n",
    "    def prepare():\n",
    "        return collections.deque()\n",
    "    \n",
    "    def run(queue):\n",
    "        for i in range(count):\n",
    "            queue.append(i)\n",
    "\n",
    "    tests = timeit.repeat(\n",
    "        setup='queue = prepare()',\n",
    "        stmt='run(queue)',\n",
    "        globals=locals(),\n",
    "        repeat=1000,\n",
    "        number=1)\n",
    "\n",
    "    return print_results(count, tests)\n",
    "\n",
    "baseline = deque_append_benchmark(500)\n",
    "for count in (1_000, 2_000, 3_000, 4_000, 5_000):\n",
    "    comparison = deque_append_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-canada",
   "metadata": {},
   "source": [
    "- the `popleft` usage scales linearly instead of displaying the super-linear behavior of `pop(0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-prisoner",
   "metadata": {},
   "source": [
    "## Item 72: Consider Searching Sorted Sequences with `bisect`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-vanilla",
   "metadata": {},
   "source": [
    "- searching for a specific value in a `list` takes linear time proportional to the list's lenght when you call the `index` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "average-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(range(10**5))\n",
    "index = data.index(91234)\n",
    "assert index == 91234"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-master",
   "metadata": {},
   "source": [
    "- if you do not know what you are searching for in alist, then you may want to search for the closest index that is equal or exceeds our goal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "powered-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(sequence, goal):\n",
    "    for index, value in enumerate(sequence):\n",
    "        if goal < value:\n",
    "            return index\n",
    "    raise ValueError(f'{goal} is out of bounds')\n",
    "    \n",
    "index = find_closest(data, 91234.56)\n",
    "assert index == 91235"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-float",
   "metadata": {},
   "source": [
    "- pythons built-in `bisect` module provides better ways to accomplush these types of searches though ordered `lists`\n",
    "- you can use the `bisect_left` function to do an eficient binary search through any sequence of sorted items\n",
    "- the index it returns will either be where the item is already present in the `list` or where you'd want to insert the item in the `list` to keep it in sorted order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "surprised-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "index = bisect_left(data, 91234) # Exact match\n",
    "assert index == 91234\n",
    "\n",
    "index = bisect_left(data, 91234.56) # Closest match\n",
    "assert index == 91235"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-cambodia",
   "metadata": {},
   "source": [
    "- the complexity of the binary search algorithm used by the `bisect` module is logarithmic\n",
    "- this means searching in a `list` of lenght 1 million takes roughly the same anount of time with `bisect` as linearly searching a list of lenght 20 using `list.index` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-concern",
   "metadata": {},
   "source": [
    "- we can verify the speed improvement for `bisect` by using `timeit` module to run a micro-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "complimentary-disclaimer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear search takes 8.595663s\n",
      "Bisect search takes 0.006658s\n",
      "1291.0x time\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import timeit\n",
    "\n",
    "size = 10**5\n",
    "iterations = 1000\n",
    "\n",
    "data = list(range(size))\n",
    "to_lookup = [random.randint(0, size)\n",
    "             for _ in range(iterations)]\n",
    "\n",
    "def run_linear(data, to_lookup):\n",
    "    for index in to_lookup:\n",
    "        data.index(index)\n",
    "\n",
    "def run_bisect(data, to_lookup):\n",
    "    for index in to_lookup:\n",
    "        bisect_left(data, index)\n",
    "\n",
    "baseline = timeit.timeit(\n",
    "    stmt='run_linear(data, to_lookup)',\n",
    "    globals=globals(),\n",
    "    number=10)\n",
    "print(f'Linear search takes {baseline:.6f}s')\n",
    "\n",
    "comparison = timeit.timeit(\n",
    "    stmt='run_bisect(data, to_lookup)',\n",
    "    globals=globals(),\n",
    "    number=10)\n",
    "print(f'Bisect search takes {comparison:.6f}s')\n",
    "\n",
    "slowdown = 1 + ((baseline - comparison) / comparison)\n",
    "print(f'{slowdown:.1f}x time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-sudan",
   "metadata": {},
   "source": [
    "- the best part about `bisect` is that its not limited to the `list` type\n",
    "- you can use it with any Python object that acts like a sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-cleaner",
   "metadata": {},
   "source": [
    "## Item 73: Know How to Use `heapq` for Priority Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-eleven",
   "metadata": {},
   "source": [
    "- sometimes you need a program to process items in order of relative importance instead\n",
    "- to accomplush this, a `priority queue` is the right tool for the job\n",
    "- lets assume I am writting a program to manage books borrowed form a library\n",
    "    - there are people constantly borrowing new books\n",
    "    - there are people returning their borrowed book on time\n",
    "    - there are people who need to be reminded to return their overdue books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "internal-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book:\n",
    "    def __init__(self, title, due_date):\n",
    "        self.title = title\n",
    "        self.due_date = due_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-forty",
   "metadata": {},
   "source": [
    "- I need a system that will send reminder messages when each book passes its due date\n",
    "- we cant use a `FIFO` queue for this because the amount of time each book is allowed to be borrowed varies based on its recency, popularity and other factors\n",
    "- for example, a book that is borrowed today may be due back later than a book thats borrowed tomorrow\n",
    "- we can achieve this behavior by using a standard `list` and sorting it by `due_date` each time a new `Book` is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "undefined-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_book(queue, book):\n",
    "    queue.append(book)\n",
    "    queue.sort(key=lambda x: x.due_date, reverse=True)\n",
    "    \n",
    "queue = []\n",
    "add_book(queue, Book('Don Quixote', '2019-06-07'))\n",
    "add_book(queue, Book('Frankenstein', '2019-06-05'))\n",
    "add_book(queue, Book('Les Misrables', '2019-06-08'))\n",
    "add_book(queue, Book('War and Peace', '2019-06-03'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-competition",
   "metadata": {},
   "source": [
    "- if we assume that the queue of borrowed books is always in sorted order, than all I need to do to check for overdue books is to inspect the final element in the `list`\n",
    "- below we define a function to return the next overdue book, if any and remove it from the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "developed-moses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein\n"
     ]
    }
   ],
   "source": [
    "class NoOverdueBooks(Exception):\n",
    "    pass\n",
    "\n",
    "def next_overdue_book(queue, now):\n",
    "    if queue:\n",
    "        book = queue[-1]\n",
    "        if book.due_date < now:\n",
    "            queue.pop()\n",
    "            return book\n",
    "    raise NoOverdueBooks\n",
    "    \n",
    "now = '2019-06-10'\n",
    "found = next_overdue_book(queue, now)\n",
    "\n",
    "(found.title)\n",
    "\n",
    "found = next_overdue_book(queue, now)\n",
    "print(found.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-portfolio",
   "metadata": {},
   "source": [
    "- if a book is returned before the due date, we can remove the scheduled reminder message by removing the Book from the `list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "relative-client",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before return ['Treasure Island']\n",
      "After return  []\n"
     ]
    }
   ],
   "source": [
    "def return_book(queue, book):\n",
    "    queue.remove(book)\n",
    "    \n",
    "queue = []\n",
    "book = Book('Treasure Island', '2019-06-04')\n",
    "\n",
    "add_book(queue, book)\n",
    "print('Before return', [x.title for x in queue])\n",
    "\n",
    "return_book(queue, book)\n",
    "print('After return ', [x.title for x in queue])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-ferry",
   "metadata": {},
   "source": [
    "- we can confirm that when all books are returned, the `return_book` function will raise the right exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "stuffed-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    next_overdue_book(queue, now)\n",
    "except NoOverdueBooks:\n",
    "    pass # Excepted\n",
    "else:\n",
    "    assert False # Doesn't happen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-guarantee",
   "metadata": {},
   "source": [
    "- the problem is that the computational complexity of this solution isn't ideal\n",
    "- although checking for and removing an overdue book has a constant cost, every time I add a book, I pay the cost of sorting the whole `list` again\n",
    "- if I have `len(queue)` books to add, and the cost of sorthing them is roughly  `len(queue) * math.log(len(queue))`, the time it takes to add books will grow superlinearly `len(queu) * len(queue) * math.log(len(queue)))` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-devil",
   "metadata": {},
   "source": [
    "- we define a micro-benchmark to measure this performance behavior experimentally by using the `timeit` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "minimal-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import timeit\n",
    "\n",
    "def print_results(counts, tests):\n",
    "    pass\n",
    "\n",
    "def print_delta(before, after):\n",
    "    pass\n",
    "\n",
    "def list_overdue_benchmark(count):\n",
    "    def prepare():\n",
    "        to_add = list(range(count))\n",
    "        random.shuffle(to_add)\n",
    "        return [], to_add\n",
    "\n",
    "    def run(queue, to_add):\n",
    "        for i in to_add:\n",
    "            queue.append(i)\n",
    "            queue.sort(reverse=True)\n",
    "\n",
    "    while queue:\n",
    "        queue.pop()\n",
    "\n",
    "    tests = timeit.repeat(\n",
    "        setup='queue, to_add = prepare()',\n",
    "        stmt=f'run(queue, to_add)',\n",
    "        globals=locals(),\n",
    "        repeat=100,\n",
    "        number=1)\n",
    "\n",
    "    return print_results(count, tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-dryer",
   "metadata": {},
   "source": [
    "- we can veify that the runtime of adding and removing books form the queue scales superlinearly as the number of books being borrowed increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "prepared-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = list_overdue_benchmark(500)\n",
    "for count in (1_000, 1_500, 2_000):\n",
    "    comparison = list_overdue_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-atlas",
   "metadata": {},
   "source": [
    "    Count 500 takes 0.001138s\n",
    "    \n",
    "    Count 1,000 takes 0.003317s\n",
    "     2.0x data size, 2.9x time\n",
    "    \n",
    "    Count 1,500 takes 0.007744s\n",
    "     3.0x data size, 6.8x time\n",
    "    \n",
    "    Count 2,000 takes 0.014739s\n",
    "     4.0x data size, 13.0x time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-skiing",
   "metadata": {},
   "source": [
    "- when a book is returned before the due date, we need to do a linear scal inorder to find the book in the queue and remove it\n",
    "- removing a books causes all subsequent items in the `list` to be shifted back an index\n",
    "- this has a high cost that also scales superlinearly\n",
    "- belowe we defien another micro-benchmark to test performance of returning a book using this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dirty-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_return_benchmark(count):\n",
    "    def prepare():\n",
    "        queue = list(range(count))\n",
    "        random.shuffle(queue)\n",
    "        \n",
    "        to_return = list(range(count))\n",
    "        random.shuffle(to_return)\n",
    "        \n",
    "        return queue, to_return\n",
    "    \n",
    "    def run(queue, to_return):\n",
    "        for i in to_return:\n",
    "            queue.remove(i)\n",
    "            \n",
    "    tests = timeit.repeat(\n",
    "        setup='queue, to_return = prepare()',\n",
    "        stmt=f'run(queue, to_return)',\n",
    "        globals=locals(),\n",
    "        repeat=100,\n",
    "        number=1)\n",
    "\n",
    "    return print_results(count, tests)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "minimal-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = list_return_benchmark(500)\n",
    "for count in (1_000, 1_500, 2_000):\n",
    "    comparison = list_return_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-webmaster",
   "metadata": {},
   "source": [
    "    Count 500 takes 0.000898s\n",
    "    Count 1,000 takes 0.003331s\n",
    "     2.0x data size, 3.7x time\n",
    "    Count 1,500 takes 0.007674s\n",
    "     3.0x data size, 8.5x time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-horizon",
   "metadata": {},
   "source": [
    "- using the methods of `list` may work for a tiny library, but it certianly wont scale to the size of a the new york public library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-interest",
   "metadata": {},
   "source": [
    "- Pyhon h as a built-in method module called `heap` that solves this problem by implementing priority queue efficiently\n",
    "- a `heap` is a data structure that allows for a `list` of items to be maintained where the computational complexity of adding a new item or removing the smallest item has logarithmic computational complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-essay",
   "metadata": {},
   "source": [
    "- in our library example, smallest means the book with the earliest due date\n",
    "- below we reimplement the `add_book` function using the `heapq` module\n",
    "- the queue is still a plain `list`\n",
    "- the `heappush` function replaces the `list.append` call from before\n",
    "- and we no longer have to call `list.sort` on the queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "occupied-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush\n",
    "\n",
    "def add_book(queue, book):\n",
    "    heappush(queue, book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-facial",
   "metadata": {},
   "source": [
    "- if we try to use this with the `Book` class as previously defined, we get this somewhat cryptic error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "perceived-drunk",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Book' and 'Book'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-a242f54708a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mqueue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0madd_book\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Little Women'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2019-06-05'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madd_book\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The Time Machine'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2019-05-30'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-68-54e4fd61a978>\u001b[0m in \u001b[0;36madd_book\u001b[1;34m(queue, book)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_book\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mheappush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'Book' and 'Book'"
     ]
    }
   ],
   "source": [
    "queue = []\n",
    "add_book(queue, Book('Little Women', '2019-06-05'))\n",
    "add_book(queue, Book('The Time Machine', '2019-05-30'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-deficit",
   "metadata": {},
   "source": [
    "- the `heapq` module requires items in the priority queue to be comparable and have a natural sort order\n",
    "- you can quickly give the `Book` class this behavior by using the `total_ordering` class decorator from the `functools` built-in module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-strap",
   "metadata": {},
   "source": [
    "- we redefine the class with a less-than method that simply compares the `due_date` fields between two `Book` instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "sustainable-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "@functools.total_ordering\n",
    "class Book:\n",
    "    def __init__(self, title, due_date):\n",
    "        self.title = title\n",
    "        self.due_date = due_date\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.due_date < other.due_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-compensation",
   "metadata": {},
   "source": [
    "- now we can add books to the priority queue by using the `heapq.heappush` function without issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "abroad-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = []\n",
    "add_book(queue, Book('Pride and Prejudice', '2019-06-01'))\n",
    "add_book(queue, Book('The Time Machine', '2019-05-30'))\n",
    "add_book(queue, Book('Crime and Punishment', '2019-06-06'))\n",
    "add_book(queue, Book('Wuthering Heights', '2019-06-12'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-ready",
   "metadata": {},
   "source": [
    "- alternatively we can create a `list` with all of the books in any order and then use `sort` method of `list` to produce the heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "integrated-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [\n",
    "    Book('Pride and Prejudice', '2019-06-01'),\n",
    "    Book('The Time Machine', '2019-05-30'),\n",
    "    Book('Crime and Punishment', '2019-06-06'),\n",
    "    Book('Wuthering Heights', '2019-06-12'),\n",
    "]\n",
    "queue.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-multiple",
   "metadata": {},
   "source": [
    "- or we can use the `heap.heapify` function to create a heap in linear time as opposed to the sort methods `len(queue) * log(len(queue))` complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heapify\n",
    "queue = [\n",
    "    Book('Pride and Prejudice', '2019-06-01'),\n",
    "    Book('The Time Machine', '2019-05-30'),\n",
    "    Book('Crime and Punishment', '2019-06-06'),\n",
    "    Book('Wuthering Heights', '2019-06-12'),\n",
    "]\n",
    "heapify(queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-navigator",
   "metadata": {},
   "source": [
    "- to check for overdue books, we inspect the first element in the `list` instead of the last and then we use the `heapq.heappop` function instead of the `list.pop` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "later-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop\n",
    "def next_overdue_book(queue, now):\n",
    "    if queue:\n",
    "        book = queue[0] # Most overdue first\n",
    "        if book.due_date < now:\n",
    "            heappop(queue) # Remove the overdue book\n",
    "            return book\n",
    "    \n",
    "    raise NoOverdueBooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-corporation",
   "metadata": {},
   "source": [
    "- now we can find and remove overdue books in order untill there are none left for the current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "established-greensboro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time Machine\n",
      "Pride and Prejudice\n"
     ]
    }
   ],
   "source": [
    "now = '2019-06-02'\n",
    "book = next_overdue_book(queue, now)\n",
    "print(book.title)\n",
    "\n",
    "book = next_overdue_book(queue, now)\n",
    "print(book.title)\n",
    "\n",
    "try:\n",
    "    next_overdue_book(queue, now)\n",
    "except NoOverdueBooks:\n",
    "    pass # Expected\n",
    "else:\n",
    "    assert False # Doesn't happen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-leeds",
   "metadata": {},
   "source": [
    "- we can write another micro-benchmark to test the performance of this implementation that uses the `heapq` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cooperative-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heap_overdue_benchmark(count):\n",
    "    def prepare():\n",
    "        to_add = list(range(count))\n",
    "        random.shuffle(to_add)\n",
    "        return [], to_add\n",
    "    def run(queue, to_add):\n",
    "        for i in to_add:\n",
    "            heappush(queue, i)\n",
    "        while queue:\n",
    "            heappop(queue)\n",
    "        \n",
    "    tests = timeit.repeat(\n",
    "        setup='queue, to_add = prepare()',\n",
    "        stmt=f'run(queue, to_add)',\n",
    "        globals=locals(),\n",
    "        repeat=100,\n",
    "        number=1)\n",
    "    \n",
    "    return print_results(count, tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-myrtle",
   "metadata": {},
   "source": [
    "- the benchmark verifies that the heap-based priority queue implementation scales much better (roughly `len(queue) * math.log(len(queue))` without superlinearly degrading performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "presidential-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = heap_overdue_benchmark(500)\n",
    "for count in (1_000, 1_500, 2_000):\n",
    "    comparison = heap_overdue_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-commercial",
   "metadata": {},
   "source": [
    "    Count 500 takes 0.000150s\n",
    "\n",
    "    Count 1,000 takes 0.000325s\n",
    "     2.0x data size, 2.2x time\n",
    "\n",
    "    Count 1,500 takes 0.000528s\n",
    "     3.0x data size, 3.5x time\n",
    "\n",
    "    Count 2,000 takes 0.000658s\n",
    "     4.0x data size, 4.4x time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-student",
   "metadata": {},
   "source": [
    "- with the `heapq` implementation the question that remains is: how should we handle `returns` that are on time?\n",
    "- the solution is to never remove a book from the priority queue untill its due date\n",
    "- at that time, it will be the first item in the `list`, and we can simply ignore the book if its already been returned\n",
    "- we implement this behavior by adding a new field to track the book's return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "satisfied-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.total_ordering\n",
    "class Book:\n",
    "    def __init__(self, title, due_date):\n",
    "        self.title = title\n",
    "        self.due_date = due_date\n",
    "        self.returned = False # New field\n",
    "        \n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.due_date < other.due_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-restriction",
   "metadata": {},
   "source": [
    "- then we change the `next_overdue_book` function to repeatedly ignore any book thats already been returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "accurate-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_overdue_book(queue, now):\n",
    "    while queue:\n",
    "        book = queue[0]\n",
    "        if book.returned:\n",
    "            heappop(queue)\n",
    "            continue\n",
    "        if book.due_date < now:\n",
    "            heappop(queue)\n",
    "            return book\n",
    "        \n",
    "        break\n",
    "    \n",
    "    raise NoOverdueBooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-variable",
   "metadata": {},
   "source": [
    "- this approach makes the `return_book` function extremely fast because it makes no modifications to the priority queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "convertible-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_book(queue, book):\n",
    "    book.returned = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-cleanup",
   "metadata": {},
   "source": [
    "- the downside to the `heapq` is that the storage overhead may take signifcant memory\n",
    "- you should plan for the worst-case by doing something like imposing a maximum numner of simultaneously lent books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-relations",
   "metadata": {},
   "source": [
    "## Consider `memoryview` and `bytearray` for Zero-Copy Interactions with `bytes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-illness",
   "metadata": {},
   "source": [
    "- its easy to use `I/O` tools the wrong way and reach the conclusion that the language is too slow for even `I/O`-bound workloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-lodge",
   "metadata": {},
   "source": [
    "- suppose we build a media server to stream television or movies over a network to users so they can watch without having to download the video data in advance\n",
    "- one key feature of such a system is the ability for users to move forward or backward in the video playback so they can skip or repeat parts\n",
    "- in client program, we can implement this by requesting a chunk of data from server corresponding to the new time index selected by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stone-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timecode_to_index(video_id, timecode):    \n",
    "    # Returns the byte offset in the video data\n",
    "    pass\n",
    "\n",
    "def request_chunk(video_id, byte_offset, size):\n",
    "    # Returns the byte of video_id's data from the offset\n",
    "    pass\n",
    "    \n",
    "video_id = \"\"\n",
    "timecode = '01:09:14:28'\n",
    "byte_offset = timecode_to_index(video_id, timecode)\n",
    "size = 20 * 1024 * 1024\n",
    "video_data = request_chunk(video_id, byte_offset, size) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-maple",
   "metadata": {},
   "source": [
    "- we also need to implement the server-side handler that receives the `request_chunk` request and returns the corresponding 20MB chunk of video data\n",
    "- for sake of simplicity, we can assume that the command and control parts of the server have already been hooked up\n",
    "- we will focus on the last steps where the requested chunk is extracted from gigabytes of video data thats cached in memeory and is then sent over the socket back to the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bulgarian-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requested_chunk_extraction():\n",
    "    socket = ... # socket connection to client\n",
    "    video_data =  ...\n",
    "    byte_offset = ...\n",
    "    size = 20 * 1024 * 1024 # Requested chunk size\n",
    "\n",
    "    chunk = video_data[byte_offset:byte_offset + size]\n",
    "    socket.send(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-complex",
   "metadata": {},
   "source": [
    "- the latency and throughput of this code will come down to two factors: how much time it takes to slice the `20MB` video chunk from `video_data` and how much time the `socket` takes to transmit that data to the client\n",
    "- if we assume that the socket is infinitely fast, we can run a micro-benchmark by using `timeit` built in module to understand the performance characteristics of slicing `bytes` instance this way to create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "patent-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def micro_benchmark():\n",
    "    def run_test():\n",
    "        chunk = video_data[byte_offset:byte_offset + size]\n",
    "        # Call socket.send(chunk), but ignoring for benchmark\n",
    "\n",
    "    result = timeit.timeit(\n",
    "        stmt='run_test()',\n",
    "        globals=globals(),\n",
    "        number=100) / 100\n",
    "\n",
    "    print(f'{result:0.9f} seconds')\n",
    "    \n",
    "# >>>\n",
    "# 0.004925669 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-tours",
   "metadata": {},
   "source": [
    "- it takes rough 5 miliseconds to extract the `20MB` slice of data to transmit to the client\n",
    "- this means the overall throughput of my server is limited to a theoretical maximum of `20MB`/`5 miliseconds` = `7.3 GB`/`second`, since that is the fastest we can extract the video data from memory\n",
    "- our server will also be limited to `1 CPU-seconds` / `5 miliseconds` = `200` clients requesting new chuncks in parallel, which is tiny compared to the tens of thousands of simultaneous connections that tools like the `asyncio` built-in module can support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-guest",
   "metadata": {},
   "source": [
    "> the problem is that slicing `bytes` instane causes the underlying data to be copied, which takes CPU time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-shame",
   "metadata": {},
   "source": [
    "- the better way to write this code is by using python builtin `memoryview` type\n",
    "- this exposes `CPython's` high-performance `buffer protocol` to the programs\n",
    "- the buffer protocol is a `low-level C` API that allows the Python runtime and `C` extensions to access the underlying data buffers that are behind objects like `bytes` instances\n",
    "- the best part about `memoryview` instance is that slicing them results in another `memoryview` instance without copying the underlying data\n",
    "- below we create a `memoryview` wrapping a `bytes` instance and inspect a slice of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "northern-membrane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<memory at 0x000001A573B44DC0>\n",
      "Size:  7\n",
      "Data in view:  b'haircut'\n",
      "Underlying data: b'shave and a haircut, two bits'\n"
     ]
    }
   ],
   "source": [
    "data = b'shave and a haircut, two bits'\n",
    "view = memoryview(data)\n",
    "chunk = view[12:19]\n",
    "print(chunk)\n",
    "print('Size: ', chunk.nbytes)\n",
    "print('Data in view: ', chunk.tobytes())\n",
    "print('Underlying data:', chunk.obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-graph",
   "metadata": {},
   "source": [
    "- by enabling `zero-copy` operations, `memoryview` can provide enormous speedups for code that need to quickly process large amounts of memory, such as numerical `C` extensions like `NumPy` and `I/O`-bount programs like the one below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-democrat",
   "metadata": {},
   "source": [
    "- below we replace the simple `bytes` slicing from the above example with `memoryview` slicing instead and repeat the micro-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "every-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000289 seconds\n"
     ]
    }
   ],
   "source": [
    "video_data = b'shave and a haircut, two bits'\n",
    "video_view = memoryview(video_data)\n",
    "byte_offset = 12\n",
    "byte_offset = 12\n",
    "size = 12\n",
    "\n",
    "def run_test():\n",
    "    chunk = video_view[byte_offset:byte_offset + size]\n",
    "    # Call socket.send(chunk), but ignoring for benchmark\n",
    "    \n",
    "result = timeit.timeit(\n",
    "    stmt='run_test()',\n",
    "    globals=globals(),\n",
    "    number=100) / 100\n",
    "print(f'{result:0.9f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-retail",
   "metadata": {},
   "source": [
    "- the result is `250` nanoseconds\n",
    "- now the theorethical max throughput of the server is `20MB`/`250 nanosecods` = `164TB`/`second`\n",
    "- for parallel clients, we can theortically support up to `1CPU-second`/`250 nanoseconds` = `4 million`\n",
    "- this means that the program is entirely bound by the underlying performance of the socket connection to the client, not by CPU constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-cardiff",
   "metadata": {},
   "source": [
    "- imagine that the data must flow in the other direction, where osme clients are sending live video streams to the server in order to broadcast them to other users\n",
    "- in order to do this, we need to store the latest video data from the user in a cache that other clients can read from\n",
    "- heres what the implementation of reading `1MB` of new data from the incoming client looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "reasonable-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_streaming():\n",
    "    socket = ... # socket connection to the client\n",
    "    video_cache = ... # Cache of incoming video stream\n",
    "    byte_offset = ... # Incoming buffer position\n",
    "    size = 1024 * 1024 # Incoming chunk size\n",
    "    chunk = socket.recv(size)\n",
    "    video_view = memoryview(video_cache)\n",
    "    before = video_view[:byte_offset]\n",
    "    after = video_view[byte_offset + size:]\n",
    "    new_cache = b''.join([before, chunk, after])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-turner",
   "metadata": {},
   "source": [
    "- the `socket.recv` method returns a `byte` instance\n",
    "- we can splice the new data with the existing cache at the current `byte_offset` by using simple slicing operations and the `bytes.join` method \n",
    "- to understand the performance of this, we can run another `micro-benchmark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "empirical-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_stream_microbenchmark():\n",
    "\n",
    "    def run_test():\n",
    "        chunk = socket.recv(size)\n",
    "        before = video_view[:byte_offset]\n",
    "        after = video_view[byte_offset + size:]\n",
    "        new_cache = b''.join([before, chunk, after])\n",
    "\n",
    "    result = timeit.timeit(\n",
    "        stmt='run_test()',\n",
    "        globals=globals(),\n",
    "        number=100) / 100\n",
    "    \n",
    "    print(f'{result:0.9f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-empire",
   "metadata": {},
   "source": [
    "- it takes 33 miliseconds to receive `1MB` and update the video cache\n",
    "- this means my maximum receive through put is `1MB`/`33 miliseconds` = `31MB` /`second` and I am limited to `31MB`/`1MB` = `31 simultaneous` clients streaming in the video data this way and does not scale "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-cycling",
   "metadata": {},
   "source": [
    "- a better way to write this code is to use Pythons built-in `bytearray` type in conjunction with `memoryview`\n",
    "- one limitation with `bytes` instance is that they are read-only and don't allow for individual indexes to be updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "changing-tattoo",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bytes' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-ddb62563245f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmy_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'hello'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmy_bytes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\x79'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'bytes' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "my_bytes = b'hello'\n",
    "my_bytes[0] = b'\\x79'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-travel",
   "metadata": {},
   "source": [
    "- the `bytearray` type is a mutable version of `bytes` that allows for arbitrary positions to be overwritten\n",
    "- `bytearray` uses integers for its values instead of `bytes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hired-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'yello')\n"
     ]
    }
   ],
   "source": [
    "my_array = bytearray(b'hello')\n",
    "my_array[0] = 0x79\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-organ",
   "metadata": {},
   "source": [
    "- a `memoryview` can also be used to wrap a `bytearray`\n",
    "- when you slice such a `memoryview` the resulting object can be used to assign data to a particular portion of the underlying buffer\n",
    "- this eliminates the copying costs from above that were required to splice the `bytes` instance back together after the data was received from the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "parental-history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'row-10 bytes- your boat')\n"
     ]
    }
   ],
   "source": [
    "my_array = bytearray(b'row, row, row your boat')\n",
    "my_view = memoryview(my_array)\n",
    "write_view = my_view[3:13]\n",
    "write_view[:] = b'-10 bytes-'\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-pepper",
   "metadata": {},
   "source": [
    "- many libraries such as `socket.recv_into` and `RawIOBase.readinto`, using the buffer protocol to receive or read data quickly\n",
    "- the benefit of these methods is that they avoid allocating memory and creating another copy of the data; \n",
    "- what's received goes straight into an existing buffer\n",
    "- Here I use the `socket.recv_into` along with a `memoryview` slice to receive data into an underlying `bytearray` without the need for splicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mature-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoryview_slice():\n",
    "    video_array = bytearray(video_cache)\n",
    "    write_view = memoryview(video_array)\n",
    "    chunk = write_view[byte_offset:byte_offset + size]\n",
    "    socket.recv_into(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-property",
   "metadata": {},
   "source": [
    "- we can run another bencmark to compare performance of this approach to the earlier example that used `socket.recv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "documented-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoryview_slice_benchmark():\n",
    "    def run_test():\n",
    "        chunk = write_view[byte_offset:byte_offset + size]\n",
    "        socket.recv_into(chunk)\n",
    "    \n",
    "    result = timeit.timeit(\n",
    "        stmt='run_test()',\n",
    "        globals=globals(),\n",
    "        number=100) / 100\n",
    "    \n",
    "    print(f'{result:0.9f} seconds')\n",
    "    \n",
    "# 0.000033925 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-steal",
   "metadata": {},
   "source": [
    "- it took 33 microseconds to receive a `1MB` video transmission\n",
    "- this means server can support `1MB`/`33 microseconds` = `31BG`/`second` of max throughput and `31GB`/`1MB` = `31,000` parallel streaming clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-saver",
   "metadata": {},
   "source": [
    "### Things to Remember"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-strategy",
   "metadata": {},
   "source": [
    "- the `memoryview` built-in type provides a zero-copy interface for reading and writing slices of objects that support Python's high-performance buffer protocol\n",
    "- the `bytearray` built-in type provides a mutable `bytes-like` type that can be used for `zero-copy` data reads with functions like `socket.recv_from`\n",
    "- a `memoryview` can wrap a `bytearray`, allowing for received data to be spliced into an arbitrary buffer location without copying costs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

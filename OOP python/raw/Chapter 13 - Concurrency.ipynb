{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lined-spencer",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-inspiration",
   "metadata": {},
   "source": [
    "- concurrency is the art of making a computer do multiple things at once\n",
    "- concurrency concepts are fairly straight fordward but the bugs that can occur are notoriously difficult to track down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-relief",
   "metadata": {},
   "source": [
    "## Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-brazilian",
   "metadata": {},
   "source": [
    "- most often concurrency is created so that work can continue happening while the program is waiting for `I/O` to happen\n",
    "- we can rely on python and the operating system to take care of the trickey switching part, while we create objects that appear to be running independently, by simultaneously\n",
    "- these objects are called `threads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deadly-begin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text and press enter: \n",
      "s\n",
      "calculated squares up to 1991670 * 1991670 = 3966745405561\n",
      "while you typed s\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class InputReader(Thread):\n",
    "    def run(self):\n",
    "        self.line_of_text = input()\n",
    "        \n",
    "print(\"Enter some text and press enter: \")\n",
    "thread = InputReader()\n",
    "thread.start()\n",
    "\n",
    "count = result = 1\n",
    "while thread.is_alive():\n",
    "    result = count * count\n",
    "    count += 1\n",
    "    \n",
    "print(f'calculated squares up to {count} * {count} = {result}')\n",
    "print(f\"while you typed {thread.line_of_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-novelty",
   "metadata": {},
   "source": [
    "- example above runs two threads\n",
    "- every program has a single thread, here we introduced another thread called `InputReader`\n",
    "- to construct a thread, we must extend the `Thread` class and implement the `run` method\n",
    "- any code executed by the `run` method happens in a seprate thread\n",
    "- the new thread does not start untill we call `.start()` method on the object\n",
    "- if we want to take out the concurrent call to see how it compares, we can call `thread.run()` in the place that we orginally called `thread.start()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-local",
   "metadata": {},
   "source": [
    "- interstingly, data we construct in one thread is accessible from other running threads\n",
    "- remember, just because a method is on a `Thread` instance does not mean it is magically executed inside that thread\n",
    "- there is a `thread.join()` method that says to _wait for the thread to complete before doing anything_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code below ensures threads wont close untill all of them finish\n",
    "for thread in threads:\n",
    "    thread.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-rebate",
   "metadata": {},
   "source": [
    "## The Many Problems With Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-rabbit",
   "metadata": {},
   "source": [
    "### Shared Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-tribute",
   "metadata": {},
   "source": [
    "- the threads have accesss to all the programs memory and thus all its variables\n",
    "- this can too easily cause inconsistencies in the program state\n",
    "- the solution to this problem in threaded programs is to `synchronize` access to any code that reads or writes a shared variable\n",
    "- synchronization works but you have to remember to try and use it and it intorduces bugs that are hard to track down"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-campaign",
   "metadata": {},
   "source": [
    "### Global Interpreter Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-internet",
   "metadata": {},
   "source": [
    "- inorder to efficiently manage memeory, garbage collection and calls to machine code, Python has a utility called the `global interpreter lock (GIL)`\n",
    "- this means threads are useless in python for the one thing they excel in other languages: `parallel processing`\n",
    "- GLI prevent any two threads from doing work at the exact same time\n",
    "- work means using the CPU, they can howerver use API calls or read data from the disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-sacrifice",
   "metadata": {},
   "source": [
    "### Thread Overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-maintenance",
   "metadata": {},
   "source": [
    "- there is also a cost of maintaing each thread\n",
    "- each thread takes up a certain amount of memory to record the state of that thread\n",
    "- switching between threads also uses some CPU time\n",
    "- this can be solved by structering our workload so that the threads can be reused to perfrom multiple jobs\n",
    "- python provides a `ThreadPool` feature to handle this\n",
    "- `ThreadPool` behaves simmilar to `ProcessPool`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-request",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-prediction",
   "metadata": {},
   "source": [
    "- Multiprocessing libary was designed to mimic the `thread` API but it has evolved to provide more robust features\n",
    "- multiprocessing is not useful when the processes spend a majority of their time waiting on `I/O` but it is the way to go for parallel computation\n",
    "- multiprocessing module spins up new operating system processes to do the work\n",
    "- this means there is an entire python interpreter running each process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "capital-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work took 0.2248551845550537 seconds\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, cpu_count\n",
    "import time\n",
    "import os\n",
    "\n",
    "class MuchCPU(Process):\n",
    "    def run(self):\n",
    "        print(os.getpid())\n",
    "        for i in range(200000000):\n",
    "            pass\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    procs = [MuchCPU() for f in range(cpu_count())]\n",
    "    t = time.time()\n",
    "    for p in procs:\n",
    "        p.start()\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    print(f\"work took {(time.time()) - t} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-platinum",
   "metadata": {},
   "source": [
    "- each Process has a `pid` number which we can get using the `os.getpid()`\n",
    "- also notice the `__name__` guardrail we put up so we dont acidentally import `MuchCPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-application",
   "metadata": {},
   "source": [
    "- the difference between `Thead` and `Process` is that process is three times faster then thread "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-device",
   "metadata": {},
   "source": [
    "## Multiprocessing Pools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-science",
   "metadata": {},
   "source": [
    "for the following reasons, you should not have more processes than there are processors on the computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-damages",
   "metadata": {},
   "source": [
    "- only `cpu_count()` process can run simultaneously\n",
    "- each process consumes resources with a full copy of the `Python` interpreter\n",
    "- communication between process is expensive\n",
    "- crating process takes a non-zero amount of time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-relay",
   "metadata": {},
   "source": [
    "- you want to create at most `cpu_count()` processes when the program starts\n",
    "- doing this on your own can be increadably difficult, but developers have done this for you in the form of `multiprocessing pools`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-integration",
   "metadata": {},
   "source": [
    "- `Pools` abstract away the overhead of figuring out what code is executing in the main process and which code is running in the subprocess\n",
    "- the pool abstration restricts number of places in which code in different processes interacts, making it much easier to keep track of\n",
    "- unlike threads, multiprocessing cannot directly access variables set up by other threads\n",
    "- pools hide the process of passing data between processes\n",
    "- using a pool looks like a function call; you pass data into a function, it is executed in another process or processes, and when the work is done, a value is returned\n",
    "- behidn the scenes, there is alot of work being done such as an object getting pickled and the pased, etc\n",
    "- pickling takes alot of time, and thus you should only pass a minumum amount of data betwen pols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "def prime_factor(value):\n",
    "    factor = []\n",
    "    for divisor in range(2, value -1):\n",
    "        quotient, remainder = divmod(value, divisor)\n",
    "        if not remainder:\n",
    "            factors.extend(prime_factor(divisor))\n",
    "            factor.extend(prime_factor(quotient))\n",
    "            break\n",
    "        else:\n",
    "            factors = [value]\n",
    "        return factor\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    pool = Pool()\n",
    "    \n",
    "    to_factor = [random.randint(10000, 5000000) for i in range(20)]\n",
    "    results = pool.map(prime_factor, to_factor)\n",
    "    for value, factors in zip(to_factor, results):\n",
    "        print(f'the factors of {value} are {factors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-friendly",
   "metadata": {},
   "source": [
    "- we first construct a multiprocessing pool isntance\n",
    "- by default this pool creates a seprate process for each of the CPU cores in the machine\n",
    "- the `map` method accepts a function and an iterable\n",
    "- the pool pickles each of the values in the iterable and passes it into an avaliable process, which executes the function on it\n",
    "- when the process is finished doing its work, it pickles the resulting list of factors and passes it back to the pool\n",
    "- then the pool has more work avaliable, it takes on the next job\n",
    "- there are funcky `await/sync` stuff you can do with the pool\n",
    "- you can also `close` a pool or `terminate` it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-universe",
   "metadata": {},
   "source": [
    "## Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-affair",
   "metadata": {},
   "source": [
    "- if we need more control over communication between processes we can use a queue\n",
    "- `Queue` data structures are useful for sending messages from one process into another processor\n",
    "- any pickled object can be sent into a `Queue`\n",
    "- this idea of a queue can acually become a distributed system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-spiritual",
   "metadata": {},
   "source": [
    "## Problem with Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-thursday",
   "metadata": {},
   "source": [
    "- primary drawback is that sharing data between processes is costly\n",
    "- excessive pickling quickly dominates processing time\n",
    "- multiprocessing works best when relatively small objects are passed between processes and a tremendous amount of work need to be done on each one\n",
    "- the other major problem, is that it can be hard to tell which process a variable or method is being accessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-singles",
   "metadata": {},
   "source": [
    "## Futures "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-scene",
   "metadata": {},
   "source": [
    "- there are also asynchronous ways of implementing concurrency\n",
    "- `Futures` wrap either multiprocessing or threading depending on which concurrency we need\n",
    "- whether you need `I/O` (threading) or `CPU` (multiprocessing)\n",
    "- `Futures` are useful for _call and answer_ type interactions\n",
    "- meaning, processing can happen in another thread and at some point in the future, you can ask it for the results\n",
    "- futures are just a wraper around multiprocessing pools and thread pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behind-ambassador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\$Recycle.Bin\\S-1-5-21-2588907532-1068130059-599424490-1001\\$IO7ZBC4.py\n",
      "C:\\Users\\Vicktree\\Desktop\\.test.py.un~\n",
      "C:\\Users\\Vicktree\\Desktop\\.test.py~.un~\n",
      "C:\\Users\\Vicktree\\Desktop\\test.py\n",
      "C:\\Users\\Vicktree\\Desktop\\test.py~\n",
      "C:\\Users\\Vicktree\\Downloads\\password_ongoing.py\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d584e51053b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mexception\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d584e51053b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                     find_files, subdir, query))\n\u001b[0;32m     32\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\concurrent\\futures\\thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[1;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m                 \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "from os.path import sep as pathsep\n",
    "from collections import deque\n",
    "\n",
    "def find_files(path, query_string):\n",
    "    subdirs = []\n",
    "    for p in path.iterdir():\n",
    "        full_path = str(p.absolute())\n",
    "        if p.is_dir() and not p.is_symlink():\n",
    "            subdirs.append(p)\n",
    "        if query_string in full_path:\n",
    "            print(full_path)\n",
    "    return subdirs\n",
    "\n",
    "query = '.py'\n",
    "futures = deque()\n",
    "basedir = Path(pathsep).absolute()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures.append(\n",
    "        executor.submit(find_files, basedir, query))\n",
    "    while futures:\n",
    "        future = futures.popleft()\n",
    "        if future.exception():\n",
    "            continue\n",
    "        elif future.done():\n",
    "            subdirs = future.result()\n",
    "            for subdir in subdirs:\n",
    "                futures.append(executor.submit(\n",
    "                    find_files, subdir, query))\n",
    "        else:\n",
    "            futures.append(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-letters",
   "metadata": {},
   "source": [
    "- the core of the program above is the event loop\n",
    "- we can construct a `ThreadPoolExector` as a context manager so that is is automatically cleaned-up and closes its threads when it is done\n",
    "- it requires a `max_workers` argument to indicate the number of threads running at the time\n",
    "- `ProcessPoolExecutor` normally is constrained to the number of CPU's on the machine, but with threads, it can be much higher, depending how many are waiting on `I/O` at the time\n",
    "- once the executor had been constructed, we submit a job to it using the root directory\n",
    "- the `submit()` method immediately returns a `Future` object, which promises to give us a result\n",
    "- the future is placed inside the queue\n",
    "- the loop then repeatedly removes the first future from the queeu and inspects it\n",
    "- if it is still running, it gets added back to the end of the queue\n",
    "- if no errors occur, we can call `result()` to get the return value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-chrome",
   "metadata": {},
   "source": [
    "## AsyncIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-generation",
   "metadata": {},
   "source": [
    "- combines the concepts of futures and event loops with the `coroutines`\n",
    "- this was specifically designed for network `I/O`\n",
    "- this library provides its own event loop\n",
    "- the cost of this event loop is that when we run code in the `async` task on the event loop, the code must return immediately\n",
    "- blocking neither on I/O nor on long-running calculation\n",
    "- AsyncIO solves this by creating a set of `coroutines` that use `async` and `await` syntax to return control to the event loop immediately when the code will block\n",
    "- the keywork replaces the `yeild`, `feild from` and `send` syntax we used with `raw coroutines`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-juvenile",
   "metadata": {},
   "source": [
    "## AsyncIO in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hybrid-scanning",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-efcc171606e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfive_sleepers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done five tasks\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \"\"\"\n\u001b[0;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[0mnew_task\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfuture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This event loop is already running'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def random_sleep(counter):\n",
    "    delay = random.random() * 5\n",
    "    print(f\"{counter} sleeps for {delay}\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"{counter} awakens\")\n",
    "    \n",
    "async def five_sleepers():\n",
    "    print(\"creating five tasks\")\n",
    "    tasks = [asyncio.create_task(random_sleep(i)) for i in range(5)]\n",
    "    print(\"Sleeping after starting five tasks\")\n",
    "    await asyncio.sleep(2)\n",
    "    print(\"Waking and waiting for five tasks\")\n",
    "    await asyncio.gather(*tasks)\n",
    "    \n",
    "asyncio.get_event_loop().run_until_complete(five_sleepers())\n",
    "print(\"Done five tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-wrong",
   "metadata": {},
   "source": [
    "- A task in this context, is an obejct that `asyncio` knows how to schedule on the event loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-hollywood",
   "metadata": {},
   "source": [
    "__This includes__:\n",
    "  - coroutines defined with the `async` and `await` syntax\n",
    "- coroutines decorated with the `@asyncio.coroutine` and using the `yeild from` syntax (deprecated in favor of the `async` and `await`\n",
    "- `asyncio.Future` objects. These are almost identical to the `concurrent.futures` but for the use with `asyncio`\n",
    "- any awaitable obkect, that is, one with an `__await__` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-advancement",
   "metadata": {},
   "source": [
    "__examining the `five_sleepers` future__:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-tamil",
   "metadata": {},
   "source": [
    "- the coroutine first constructs five instances of the `random_sleep` coroutine\n",
    "- these are wrapped in a `asyncio.create_task` call, which adds the future to the loops taks queue so they can execute and start immediately, when control is returned to the loop\n",
    "- the control is returned whenever we call `await`\n",
    "- in this case, we call `await asyncio.sleep` to pause the execution of the coroutine for two seconds\n",
    "- during the break, the event loop executes the taks that it has queue up, namely the five `random_sleep` tasks\n",
    "- when the sleep call in the `five_sleepers` task wakes up, it calls `asyncio.gather`. this function accepts tasks as `varargs` and awaits each of them before returning\n",
    "- each of the `random_sleep` coroutines prints a starting message, then sends control back tot he event loop for a specific amount of time using its own `await` call\n",
    "- when the sleep has completed, the event loop passes contorl back tot he relevent `random_sleep` tasks, which prints its awakening message before returning\n",
    "- when the event queue is empty, the `run_until_complete` call is able to terminate and the program ends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-bibliography",
   "metadata": {},
   "source": [
    "- `async` keyworkd acts as documentation notifiying the python interpreter that the coroutine contains the `await` calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-punch",
   "metadata": {},
   "source": [
    "## Reading an AsyncIO Future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-woman",
   "metadata": {},
   "source": [
    "- an AsyncIO coroutine executes each line in order untill it encounter an `await` statement at which point, it returns control to the event loop\n",
    "- the event loop then executrs any other tasks that are ready to run, including the one that the orginal coroutien was waiting on\n",
    "- whenever that child task completes, the event loop sends the result back into the coroutine so that it can pick up execution untill it encounters another await statement or returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-fiction",
   "metadata": {},
   "source": [
    "## AsyncIO for Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-routine",
   "metadata": {},
   "source": [
    "- AsyncIO was specifically designed for use with network sockets\n",
    "- AsyncIO networking resolves around the intimately linked concepts of transporting and protocols\n",
    "- a protocal is a class that has specific methods that are called when relevant events happen\n",
    "- Since DNS runs on top of `UDP` __(User Datagram Protocol)__, we build our protocol class as a subclass of `DatagramProtocol`\n",
    "- the transport essentially represents a communication stream\n",
    "- behind the scenes the transport has set up a task on the event loop that is listening for incomming `UDP connections`\n",
    "- all we have to do, then is start the event loop running with the call to `loop.run_forver()` so that the task can process these packets\n",
    "- when the packets arrive, they are processed on the protocol and everything just works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-contractor",
   "metadata": {},
   "source": [
    "- there is alot of boilerplate in setting up a protocol class and the underlying transport\n",
    "- AsyncIO provides an abstraction on top of these two key concepts, called __streams__\n",
    "- we will see an example of streams in the TCP server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-familiar",
   "metadata": {},
   "source": [
    "## Using Executors to Wrap Blocking Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-flashing",
   "metadata": {},
   "source": [
    "- AsyncIO provides its own version of hte futures library to allow us to run code in a separate thread or process when there is not an appropriate non-blocking call to be made\n",
    "- this allows us to combine threads and processes with the asynchronous model\n",
    "- this is useful when an application has bursts of `I/O` bound and CPU-bound activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-infrared",
   "metadata": {},
   "source": [
    "## Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-civilization",
   "metadata": {},
   "source": [
    "- below is description of code I chose not to include due to its verbosity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-madness",
   "metadata": {},
   "source": [
    "- `create_server` hooks inot AsyncIOs strams  instead of using the underlying transport/protocol code\n",
    "- it allows us to pass in a normal coroutine, whihc receives reader and writer parameters\n",
    "- these both represent streams of bytes that can be read from and written, like files or sockets\n",
    "- secondly, because this is a TCP server, instead of __UDP__, there is some socket cleanup requied\n",
    "- this cleanup is a blocking call, so we have to run `wait_closed` coroutine on the event loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-diary",
   "metadata": {},
   "source": [
    "- Streams reading is a potentially blocking call so we have to call it with `await`\n",
    "- writing doesent blokc; it just puts the data in  queue, which AsyncIO sends out in the background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-equality",
   "metadata": {},
   "source": [
    "## AsyncIO clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-triumph",
   "metadata": {},
   "source": [
    "- because it can handle many thousands of simultaneous connections, `AsyncIO` is a very common for implementing servers\n",
    "- clients can be much simpler than servers, as they dont have to be set up to wait for incomming connections\n",
    "- like most networking libraries, you just open a conenction, submit your requests and process any responses\n",
    "- the main difference is that you need to use `await` any time you make a potientally blocking call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "novel-bibliography",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ee1349fe2c32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_sort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \"\"\"\n\u001b[0;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[0mnew_task\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfuture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\vicktree\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36m_check_running\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This event loop is already running'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import json\n",
    "async def remote_sort():\n",
    "    reader, writer = await asyncio.open_connection(\"127.0.0.1\", 2015)\n",
    "    print(\"Generating random list...\")\n",
    "    numbers = [random.randrange(10000) for r in range(10000)]\n",
    "    data = json.dumps(numbers).encode()\n",
    "    print(\"List Generated, Sending data\")\n",
    "    writer.write(len(data).to_bytes(8, \"big\"))\n",
    "    writer.write(data)\n",
    "    \n",
    "    print(\"Waiting for data...\")\n",
    "    data = await reader.readexactly(len(data))\n",
    "    print(\"Received data\")\n",
    "    sorted_values = json.loads(data.decode())\n",
    "    print(sorted_values)\n",
    "    print(\"\\n\")\n",
    "    writer.close()\n",
    "    \n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(remote_sort())\n",
    "loop.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contiguous vs. Linked List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Contiguously Allocated Structures__:\n",
    "> Are composed of single slabs of memory and include arrays, matricies, heaps and hash tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Linked Data Structure__:\n",
    "> Are composed of distinct chunks of memory bound together by pointers and include lists, trees, and graph adjacency list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array is the fundamental contiguously-allocated data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are fixed size and each element can be located by its index or equivalently adress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Array Advantages__:\n",
    "- Constant-time access given the index\n",
    "    - because the index of each element maps directly to a particular memory adress, we can access arbitrary data items instantly provided we know the index\n",
    "- Space efficency\n",
    "    - Arrays consist purely of data, so no spaced is wasted with links or other formatting information. End of record information is also not needed because we know of the size beforehand\n",
    "- Memory Locality\n",
    "    - A common programming idiom involved iterating through all the elements of a data structure. Arrays are good for this because they exhibit excellent memory locality. Physical continuity between successive data accesses helps exploit the cache-memory on modern computers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic arrays actually allow us to enlarge arrays as we need them. What we do is simply make a new array $ 2X $ the previous arrays size and copy everything over to the new array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the doubling involved and thing $ logs $. It will take $ log_2(n) $ doubling untill the arrays get to have $ n $ positions. Of course in reality, each element moves only two times on average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total work managing the dynamic array is the same $ O (n )$ as it would have been if a single array of sufficient size had been allocated in advance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/01.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary thing lost using dynamic arrays is guarantee that each array access takes constant time in the _worst case_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your basically amortizing the costs. The doubling price is spread over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointers and Linked Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pointers are the connections that hold the pieces of linked structures together. They represent adress of location in memory. A special NULL pointer value is used to denote structure-terminating or unassigned pointers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/02.png\" width=600></center>\n",
    "\n",
    "__Figure 1__: Linked list example showing data and pointer fields  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each node in our data structure contains one or more data feilds that retain the data that we need to store\n",
    "- Each node contains a pointer feild to at least one other node. This means that much of the space used in linked data structre has to be devoted to pointers, not data\n",
    "- Finally, we need a pointer to head of the structure, so we know where to access it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching A List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for a item $ x $ in a linked list can be done iteratively or recursively. We do this untill we reach the  $ NULL $ or $ 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    list *search_list(list *l, item_type x)\n",
    "    {\n",
    "        if (l == NULL) return(NULL);\n",
    "        \n",
    "        if (l->item == x)\n",
    "            return(l);\n",
    "        else\n",
    "            return( search_list(l->next, x) );\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insertion at the beginning of the list avoids any need to traverse the list, but does require us to update the pointer to the head of the data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    void insert_list(list **l, item_type x)\n",
    "        {\n",
    "        list *p; /* temporary pointer */\n",
    "        \n",
    "        p = malloc( sizeof(list) );\n",
    "        p->item = x;\n",
    "        p->next = *l;\n",
    "        *l = p;\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First, the `malloc` function allocates a chunk of memory of sufficient size  for a new node to contain $ x $\n",
    "* Secondly, the funny double star $ (**1) $ denotes that $ 1 $ is a pointer to a pointer to a list node. The last line $ *1 = p $ copies $ p $ to the place pointed to $ 1 $, which is the external variable maintaining access to the head of the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletion form a linked list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find a pointer to predecessor of the item to be deleted\n",
    "- the predecessor is needed because it points to the doomed node, so its $ next $ pointer must changes.\n",
    "- the deletion is easy, one the node is found, just take care to reset the pointer to the head of the list $ 1 $ when the first element is deleted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        list *predecessor_list(list *l, item_type x)\n",
    "        {\n",
    "            if ((l == NULL) || (l->next == NULL)) {\n",
    "                printf(\"Error: predecessor sought on null list.\\n\");\n",
    "                return(NULL);\n",
    "        }\n",
    "        \n",
    "        if ((l->next)->item == x)\n",
    "            return(l);\n",
    "        else\n",
    "            return( predecessor_list(l->next, x) );\n",
    "        }\n",
    "        \n",
    "        \n",
    "        delete_list(list **l, item_type x)\n",
    "        {\n",
    "            list *p; /* item pointer */\n",
    "            list *pred; /* predecessor pointer */\n",
    "            list *search_list(), *predecessor_list();\n",
    "\n",
    "            p = search_list(*l,x);\n",
    "            if (p != NULL) {\n",
    "                pred = predecessor_list(*l,x);\n",
    "                if (pred == NULL) /* splice out out list */\n",
    "                    *l = p->next;\n",
    "                else\n",
    "                    pred->next = p->next;\n",
    "                free(p); /* free memory used by node */\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparsion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Linked List Pros__:\n",
    "- Overflow on linked structures can never occur unless the memory is actually full\n",
    "- Insertion and deletions are simpler than for contigious lists\n",
    "- With large records, moving pointer is easier and faster than moving the items themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Static Array Pros__:\n",
    "- Linked structures require extra space for storing pointer fields\n",
    "- Linked Lists do not allow effcient random access to items\n",
    "- Arrays allow better memory locality and cace performance than random pointer jumping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Objects: Lists and arrays can be though of as recursive objects:\n",
    "- __Lists__: Chopping the first element off a linked list leaves a smaller linked list. The same argument works for strings and since removing characters from string and leaves a string. Lists are recursive objects\n",
    "- __Arrays__: Splitting the first $ k $ elements off an $ n $ element array gives two smaller arrays of size $ k $ and $ n - k $ respectively. Arrays are recursive objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The significance of thinking of them as recursive objects is that they lead to simpler list processing and effcient divide-and-conquer algorithms such as quicksort and binary search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacks and Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the term _container_ to denote a data structure, that permits storage and retrivel of data items _independent of content_. Containers are distinquished by their particular retrieval order they support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Stacks__:\n",
    "> Support retrieval by last-in, first-out (LIFO) order. Stacks are simple to implement and very and very efficent. For this reason, stacks are probaly the right container to use when retrieval order dosen't matter at all, such as when processing batch jobs. The put and get operations for stacks are usually called push and pop\n",
    "- Push(x, s): Insert item $ x $ at the top of stack $ s $\n",
    "- Pop(s): Return (and remove) the top item of stack $ s $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ LIFO $ order arises when you have to execute recursive algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Queues__:\n",
    "> Support retrivel in first in, first out (FIFO) order. The purpose of this order is the minimize the max time spent waiting. The average time will be the same regardless of whether FIFO or LIFO is used. Order is important\n",
    "- Enqueue(x, y): Insert item $ x $ at the back of queue $ q $\n",
    "- Dequeue(q): Return (and remove) the front item from queue $ q $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _dictionary_ data type permits access to data items by content. You stick an item into a dictionary so you can find it when you need it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Operations__:\n",
    "- Search(D, k): Given a search key $ k $, return a pointer to the element in dictionary $ D $ whose key value is $ k $ if one exists\n",
    "- Insert(D, x): Given a data item $ x $, add it to the set in the dictionary $ D $\n",
    "- Delete(D, x): Given a pointer to a given data item $ x $ in the dictionary $ D $, remove it from $ D $\n",
    "- Max(D) or Min(D): Retrives the item with the largest (or smalelst) key from $ D $. This enables the dictionary to serve as a priority queue\n",
    "- Predecessor(D, k) or Successor(D, k): Retrieve the item from $ D $ whose key is immediately before (or after) $ k $ in sorted order. These enable us to iterate through the elements of the data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More powerful dictionary Implementations exist such as binary search trees and hash tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Sorted vs. Unsorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/03.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Search__:\n",
    "    - Implemented by testing the search key $ k $ against each element of an unsorted array. Thus search takes linear time in the workst case, which is when the key $ k $ is not found in $ A $\n",
    "- __Insertion__: \n",
    "    - Implemented by incrementing $ n $ and then copying item $ x $ to the $ nth $ cell in the array, $ A[n] $. The bulk of the array is untouched, so this operation takes constant time\n",
    "- __Deletion__: \n",
    "    - We do not need to find the element to delete (because we have index) but we do need to shift once its deleted if its is not in the end.  So a clever tick is simply to just write over $ A[x] $ and the decrement $ n $. This only take constant time\n",
    "- __Pre-/Successor__: \n",
    "    - refer to the item appearing before/after $ x $ in sorted order. In an unsorted array, the elements physical predecessor is not necessarily its logical predecessor. Both require a sweep through all $ n $ elements of $ A $ to determine the winner\n",
    "- __Min/Max__: \n",
    "    - are defined with respect to sorted order, and so require linear sweeps to identiy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sort the order, we completely reverse the time complexities. Searches can now be done in $ O(log n) $ time, using binary search because we know the median element.  The search continues recursively on the appropiate position. Number of halving of $ n $ untill we get to a single element is $ [lg n]$. Insertion and deletion become expensive because we cant just simply cope the value and reduce size of the array, we must move large portions of the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries on Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/04.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Insertion/Deletion__:\n",
    "    - difficult on singly linked list because we need pointer to previous. Thus we must spend linear time searchig for it. Deletion is faster for sorted doubly-linked list than sorted arrays, because splicing out the deleted element from the list is more effcient than filling the hole by moving array elements. The predecessor pointer problem again complicates deletion from singly-linked sorted lists\n",
    "- __Search__:\n",
    "    - Sorting provides less benefit for linked lists than it did for arrays. Binary search is no longer possible, becase use can't access the median element without traversing all the elements before it. \n",
    "- __Traversal Operations__: \n",
    "    - the predecessor pointer problem again complicates implementing predecessor.  In sorted lists, the pre/succ can be implemented in constant time\n",
    "- __Maximum__: \n",
    "    - The maximum element sits at the tail of the list, which would normally require $ Θ(n) $ time to reach in either singly or doubly-linked lists. We can maintain a separate ponter to the list tail, provided we pay the maintence costs for this pointer on every insertion and deletion. The tail pointer can update in costant time on doubly-linked lists (on insertion check whether last is next or still NULL; on deletion set last to point to the list predecessor of last if last element is deleted). On singly-linked lists, we cannot find predecessor but the the max is on average O (1) because we put the charge on each deletion, which is already linear time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Search Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/05.png\" width=400></center>\n",
    "\n",
    "__Figure 2__: The five distinct binary search trees on three nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have had data structures that allow fast search or flexable update but not fast search and flexable update. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary search requires that we have fast access to two elements, specifically the median elements above and below the given node. To combine these idea, we need a \"linked list\" with two pointers per node. This is the basic idea behind binary search trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rooted binary tree is recursively defined as either $ (1) $ empty or $ (2) $ consisting of a node called the root, together with two rooted binary trees called the left and right subtrees, respectibely.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary search tree labels each node in a binary tree with a single key such that for any node labled $ x $, all nodes in the left subtree of $ x $ have $ keys < x $ while all nodes in the right substree of $ x $ have $ keys > x $. This labeling is what makes it a BST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BST Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary trees have `left` and `right` pointer feilds and an optional `parent` pointer and a data feild. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/06.png\" width=600></center>\n",
    "\n",
    "__Figure 3__: Relationships in a binary search tree (left). Finding the minimum and maximum elements in a binary search tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    typedef struct tree {\n",
    "        item_type item; /* data item */\n",
    "        struct tree *parent; /* pointer to parent */\n",
    "        struct tree *left; /* pointer to left child */\n",
    "        struct tree *right; /* pointer to right child */\n",
    "    } tree;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching in a Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BST tree labeling uniquely identites where each key is located. Start at the root, unless its the key you want, proceede either left or right depending upon whether $ x $ occurs before or after the root key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works due to the recursive nature of the BST structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    tree *search_tree(tree *l, item_type x)\n",
    "    {\n",
    "        if (l == NULL) return(NULL);\n",
    "        \n",
    "        if (l->item == x) return(l);\n",
    "        \n",
    "        if (x < l->item)\n",
    "            return( search_tree(l->left, x) );\n",
    "        else\n",
    "            return( search_tree(l->right, x) );\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search algorithm runs in $ O (h) $ time, where $ h $ denotes the height of the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Min and Max Elements in a Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By definition, the smallest key must reside in the left subtree of the root, since all keys in the left subtree have values less than that of the root. The minimum element must be leftmost descent of the root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    tree *find_minimum(tree *t)\n",
    "    {\n",
    "        tree *min; /* pointer to minimum */\n",
    "        if (t == NULL) return(NULL);\n",
    "        \n",
    "        min = t;\n",
    "        while (min->left != NULL)\n",
    "            min = min->left;\n",
    "        return(min);\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversal in a Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary search trees make it easy to report the labes in a sorted order. By definition all the keys smaller than the root must lie in the left subtree of the root and all keys bigger than the root in the right subtree. Thus visiting the nodes recursively in accord with such a policy produces an $ in-order $ traversal of the search tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    void traverse_tree(tree *l)\n",
    "        {\n",
    "        if (l != NULL) {\n",
    "            traverse_tree(l->left);\n",
    "            process_item(l->item);\n",
    "            traverse_tree(l->right);\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item is processed once during the course of traversal, which runs in $ O(n) $ time, where $ n $ denotes the number of nodes in the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insertion In a Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one palce to insert an item $ x $ into a BST $ T $ where we know we can find it again. We must place the $ NULL $ pointer found in $ T $ after an unsuccessful query for the key $ k $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Insert Tree__:\n",
    "- a pointer $ l $ to the pointer linking the search subtree to the rest of the tree\n",
    "- the key $ x $ to be inserted\n",
    "- a $ parent $ pointer to the parent node containing $ l $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the node is allocated and linked in on hitting the $ NULL$ pointer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we pass the pointer to the appropiate left/right pointer in the node during the search, so the assignment $ *l = p $; links the new node into the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    insert_tree(tree **l, item_type x, tree *parent)\n",
    "    {\n",
    "    \n",
    "    tree *p; /* temporary pointer */\n",
    "\n",
    "    if (*l == NULL) {\n",
    "        p = malloc(sizeof(tree)); /* allocate new node */\n",
    "        p->item = x;\n",
    "        p->left = p->right = NULL;\n",
    "        p->parent = parent;\n",
    "        *l = p; /* link into parent’s record */\n",
    "        return;\n",
    "    }\n",
    "    \n",
    "    if (x < (*l)->item)\n",
    "        insert_tree(&((*l)->left), x, *l);\n",
    "    else\n",
    "        insert_tree(&((*l)->right), x, *l);\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocating the node and linking it in the tree is a constant-time operation after the search has been performed in $ O (h) $ time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletion from a Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/07.png\" width=700></center>\n",
    "\n",
    "__Figure 4__: Deleting tree node with $ 0 $, $ 1 $ and $ 2 $ children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting it hard because it meand relinking it descendants subtrees back into the tree somewhere else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If leaf nodes have no children, it may be deleted by simply clearing the pointer to the given node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having only one chold is straightfordward, there is one parent and one grandchild, and we can link the grandchild directly to the parent without violating the in-order labeling proprty of the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trickey part is when you have two children.  One solution is to relabel this node with the key of its immediate succesor in sorted order. The successor must be the smalles key value in the right subtree, specifically the leftmost descendant in the right subtree $ (p) $. Moving this to the point of eletion results in a proprly-labeled binary search tree and reduces our deletion problem to physically removing a node with at least one child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every deletion requirres the cost of at most two search operations, each talking $ O(h) $ time where $ h $ is the height of the tree, plus a constant amount of pointer manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Good Are Binary Search Trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When implemented using binary search tree, all three dictionary operations take $ O(h) $ time, where $ h $ is the height of the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest height we can hope for occurs when the tree is perfectly balanced, where $ h = [log n] $. But the tree must be balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The insertion algorithms puts each new item at a leaf ndoe where it should have been found. This makes the shape (and more importantly height) of a tree a function of the order in which we insert the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert is bad because it may produce a skewed tree. Imagine the following operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ insert(a) -> insert(b) -> insert(c) -> insert(d) -> $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would make a skinny linear height tree where only right pointers are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely our insert time will be $  O (log n) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Search Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are algorithms that can guarantee the height of the tree is always $ O (log n) $. And therefore all dictionary operations (insert, delete, query) take $ O (log n) $ time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priority Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprity Queues are data structures that provide more flexibility than simple sorting, because they allow new elements to enter a system at arbitrary intrvals. It is much more cost-effective to insert a new job into priority queue then to re-sort everything on each such arrival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Operations__:\n",
    "- Insert(Q, x):\n",
    "    - Given an item $ x $ with key $ k $, insert it into the priority queue $ Q $\n",
    "- Find-Max/Min(Q):\n",
    "    - Return a pointer to the item whos key value is smaller/larger than any other key in the priority queue $ Q $\n",
    "- Delete-Min/Max(Q):\n",
    "    - Remove the item from the priority Queue $ Q $ whose key is min/max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proproty Queue Time Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/08.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All priority queue deletions involve only the minimum element. By storing the sorted array in reverse order (largest value on top), the min element will be the last one in the array. Deleting the tail element requires no movment of any items, just decrementing the number of remaining items $ n $, and so delete-minimum can be implemented in constant time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above claims that we can implement find-minimum in constant time for each data structure. The trick is using an extra variable to store a pointer/index to the min enetry in each of these structures. We just return the value when asked to find-min. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the new min value if we deleted the old one takes log take linar time in an unsorted array and log time on a tree. This is because we amortize the cost with the delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A heap is a particular type of a priortiy queue implementation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing and Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash tables are a very pratical way to maintain a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In python a dictionary implements a hash table underneath it all. The advantage over an array is $ O (1) $ lookup. So if i want to look up a value in an array, i must first loop through the array and when it gets to the value, return it. This can take $ O (n) $ time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hask tables exploit the fact that an item up in an array takes constant time once you have its index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hash function is a mathematical function that maps keys to integers. We will use the value of our hash function as an index into an array, and store our item at that position "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of the hash function is usually to map each key to a big integer. Let $ a $ be the size of the alphabet on which a given string $ S $ is written. Let $ char(c) $ be a function that mpas each symbol of the alphabet to a unique interger from $ 0 $ to $ a - 1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/09.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above maps each string to a unique (but large) integer by treating the characters of the string as \"digets\" in a $ base-a $ number system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a unique identifier numbers, but they are so large thay will exceed the number of slots in our hash table $ m $. We must reduce this number to an integer between $ 0 $ and $ m - 1 $ by taking the remainder of $ H(S) $ mod $ m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the table size is selected with engough finesse ($ m $ is a large prime not close to $ 2^i - 1 $, the resulting hash values should be fairly uniformly distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collision Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two distinct keys may hash to the same value. _Chaining_ is the easiest approach to collision resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/10.png\" width=600></center>\n",
    "\n",
    "__Figure 5__: Collision resolution by chaining "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent the hash table as an array of $ m $ linked lists as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $ ith $ list will contain all the items that hash to the value of $ i $. Thus search, insertion and deletion reduce to the corresponding problem in linked lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the $ n $ keys are distributed uniformly in a table, each list will contain roughly $ n/m $ elements, making them a constant size when $ m = n $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaining is very natural, but devotes a considerbale amount of memory to pointers. This is space that could be used to make the table larger, and hence the \"lists\" smalelr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Adressing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/11.png\" width=500></center>\n",
    "\n",
    "__Figure 6__: Collision resolution by open adressing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Alternative to chaining is open adressing. The hash table is maintained as an array of elements (not buckets), each initialized to $ NULL $, as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On insertion, we check to see if the desired position is empty or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If empty, we insert. Else we find another place for insert. The simplest technique called _sequential probing_ inserts the item in the next open spot in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the table is not too full, the contiguous runs of items should be fairly small, hence this location should be only a few slots from its intended position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for a given key now involves going to the appropriate hash vaule and checking to see if the item there is the one we want. If its there, return it or keep checking through the lenght of the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletion in an open adressing scheme can get ugly, since removing one element might break a chain of insertions, making some elements inaccessible. We have no alternative but to reinsert all the items in the run following the new hole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaining and open adressing both require $ O (m) $ to initialize an $m$-element hash table to null elements prior to the first insertion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traversing all the elements in the table takes $ O(n + m ) $ times for chaining, because we have to scan all $ m $ buckets looking for elements, even if the actual number of inserted items is small. This reduces to $ O (m) $ time for open adressing since $ n $ must be at most $ m $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using chaining with doubly-linked lists to resolve collisions in an $ m$-element hash table, the dictionary operations for $ n $ items can be implemented in the following expected and worst case times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/12.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pragmatically, a hash table is often the best data structure to maintain a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficent String Matching via Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strings are sequences of characters where the order of the characters matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary data structure for representing strings in an array of characters. This allows for constant-time access to the $ ith $ character of the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally for substring matching, the time complexity can be $ O (nm) but we can expect linear time using Rabin-Karp algorithm, which is based on hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we compute a given hash function on both the pattern sting $ p $ and the $ m$-charcter substring starting from the $ ith $ position. If the strings are identical, the resulting hash values must be the same, else they are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily spend the $ O(m) $ time it takes to explicitly check the identity of two strings whenever the hash value agree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The catch is that it takes $ O (m) $ time to compute a hash function and thus we are left with $ O(mn) $ algorithm again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets apply the previously defined hash function to the $ m $ characters starting from the $ jth $ position of string $ S $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/13.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What changes if we now try to compute $ H(S, j + 1)$? The hash of the next window of $ m $ characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little algebra reveals that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/chap3/14.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that once we know the hash value form the $ j $ position, we can find the hash value from the (j + 1)st position for the cost of two multiplications, one addition and one subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done in constant time (the value of $a^m-1$ can be computed once and used for all hash value computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rabin-Karp is a good example of a randomized algorithm (if we pick $ M $ in some random way; $ M $ is a reasonably large prime number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no guarantee that the algorithm runs in $ O(n + m) time, because we may get unlucky and have the hash values regularly collide with spurious matches. But the odds are so great that there will be no collision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Detection via Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key idea of hashing is to represent a large object (be it a key, string or a substring) using a single number. The goal is a representation of the large object by an entity that can be manipulated in constant time, such tht it is relatively unlikely that two different large objects map to the same value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features of Hashing:\n",
    "- Tells you if a document is different from all the rest in a large corpus?\n",
    "- Tells us if the document is plagiarized rom a document in a large corpus?\n",
    "- Uses cryptographic hashing to make sure no one reads the bids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specialized Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __String Data Structures__:\n",
    "    - Character stings are typically represented by arrays of characters, sometime with a special character to mark the end of a string. Suffix trees/arrays are special data structures that preprocess strings to make pattern matching operations faster\n",
    "- __Geometric Data Structures__:\n",
    "    - Geometric data types typically consists of collections of data points and regions. Regions in the place can be described by polygons where the boundary of the polygon is given by a chain of line semgents. Polygons can be represented using an array of points $ (v_1, ..., v_n, v_1) $, such that $ (v_i, v_i+1) $ is a segment of the boundary. Spatial data structures such as $ kd-trees $ organize points and regions by geometric locations to support fast search\n",
    "- __Graph Data Structures__: \n",
    "    - Graphs are typically represented using either adjaceny matrices or adjacency lists. The choice of representation can have a substantial impact on the design of the resulting graph algortihm\n",
    "- __Set Data Structure__:\n",
    "    - Subset of items are typically represented using a dictionary to support fast membership queries. Alternately, bit vectors are boolean arrays such that the $ ith $ bit represents true if $ i $ is in the subset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chap12/00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A set of n records, each identified by one or more key fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and maintain a data structure to efficiently locate,\n",
    "insert, and delete the record associated with any query key q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many ways to implement dictionaries. In paratice though, it is important to avoid using bad data structures then to identify the single best option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the implementation of the dictionary data structure from its interface. Use explicit calls to methods or subroutines that initialize search and modify the data structure, rather than embedding them within code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many items will you have in your data structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many items will you have in your data structure? \n",
    "- Do you know the relative frequencies of insert, delete, and search operations?\n",
    "- Can we assume that the access pattern for keys will be uniform and random?\n",
    "- Is it critical that individual operations be fast, or only that the total amount of work done over the entire program be minimized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation/Descisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Unsorted linked lists or arrays__:\n",
    "    - For small data sets, an unsorted array is probably the easiest data structure to maintain. Linked structures can have terrible cache performance compared with sleek, compact arrays.  Once your dictionary becomes larger than 50 to 100 items, the linear search will kill you for either lists or arrays. A useful variant is called the _self-organizing list_ or the LRU Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Sorted Linked Lists or Arrays:__\n",
    "    - Maintaining a sorted linked list is not worth the effort unless you are trying to eliminate duplicates since we cannot perform a binary search in such data structures. Works only if there are not too many insertions or deletions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Hash Tables__: Anything with $ 100$ to $ 10,000,000 $  keys, a hash table is probably the right way to go. We use a function that maps keys to integers between $ 0 $ and $ m-1 $. We maintain an array of $ m $ buckets each typically implemented using an unsorted linked list. The hash function immediately identifies which bucket contains a given key. If we use a hash function that spreads the key out nicely, and a sufficently large hash table, each bucket should contain very few items, this making linear search acceptable. \n",
    "\n",
    "    - How do i deal with collisions? Open adressing can lead to more concise tables with better cache performance than vucketing, but performance will be more brittle as the load  factor (ratio of occupancy to capacity) of the hash table starts to get hight\n",
    "    - How big should be the table? With bucketing $ m $ should be the same size as the max number of items you except to put in the tabl . With open adressing, make it about $ 30 $ precent larger or more. Selecting $ m $ to be a prime number minimizes the dangers of a bad hash function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Binary Search Trees__:\n",
    "    - elegant data structures that support fast insertions, deletions and queries. In a random search tree, we simply insert a node at the leaf position where we can find it and no rebalancing takes places. Balanced search treees use local rotation operations to restructure search trees, moving more distant nodes closer to the root while maintaining the in-order search structure of the tree. Among balanced search trees, $ AVL $ and $ 2/3 $ trees are now passe and red-black trees seem more popular ._splay tree_ is an intersting self-organizing data structure which uses rotations to move any accessed key to the root. Frequently used or recently accessed nodes thus sit near the top of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __B-Trees__: \n",
    "    - For data so large that will not fit in memeory, your best bet is the __B-tree__. Once data has been stored outside of main memeory, the search time grows by several orders of magnitude. Idea behind a _B-tree_ is to collapse several levels of a binary searh tree into a single large node, so that we can make the equivalent of several search steps before another disk access is needed. It is important to understand how the secondary storage device and virtual memory interact. _Cache-oblivious algorithms can migate such concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Skip Lists__\n",
    "    - THese are somewhat a cult of data structures. A hierarchy of sorted linked lists is maintained, where a coin is flipped for each element to decide whether it gets copied into the next highest list. This implies roughly $ lg n $ lists, each roughly half as large as the one above it. Easier to use analyze and implement relative to balanced trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# priority Queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chap12/01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of records with numerically or otherwise totally-ordered keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and maintain a data structure for providing quck access to the _smallest_ or _largest_ key in the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Called \"priority\" queues because they enable you to retrieve items not by insertion time (as in stack or queue), nor by key match (as in dictionary) but by which item has the highest priority of retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If application performs no insertions after initial query, there is no need for an explicit priority queue. Simply sort the records by priority and proceed from top to bottom, maintaining a pointer to the last record retrieved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __What other operations do you need__?\n",
    "    - Will you be search for arbitrary keys, or just searching for the smallest? Will you be deleting arbitrary elements from the data, or just repeatedly deleting the top or smallest item?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Do you know the maximum data structure size in advance?__ \n",
    "    - The issue here is whether you can preallocate space for the data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Might you change thr priority of elements already in the queue?__\n",
    "    - Changing the priority of elements implies that we must be able to retrieve elements from the queue based on their key, in addition to being able to retrieve the largest element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation/Descisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Sorted array or list__:\n",
    "    - A sorted array is very eddicient to both identify the smallest element and delete it by decrementing the top index. Howerver, maintaining the total order makes inserting new elements slow. Sorted arrays are only suitable whne there will be few insertings into the priority queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Binary heaps__\n",
    "    - The simple, elegant data structure supports both insertion and extract-min in $ O (lg n) $ time each. Heaps maintain an implicit binary search tree structure in an array, such that the key at the root of the subtree is less  than all of its descendents. Thus the minimum key always sits at the top of the heap. New keys can be inserted by placing them at an open leaf an percolating the element upwards untill it sits at its proper place in the partial order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bounded height priority queue__:\n",
    "    - This array-based data structure permits constant-time insertion and find-min operations whenever the range of possible key value is limited. Suppose we know that all key values will be integers between $ 1 $ and $ n $. We can set up an array of $ n $ linked lists, such that the $ ith $ list serves as a bucket containing all items with key $ i $. We will maintain a top pointer to the smallest nonempty list. To insert an item with key $ k $ into the priority queue, add it to the $ kth $ bucket and set $ top= min(top, k)$. To extract the minimum, report the first tiem from bucket _top_, delete it and move _top_ down if the bucket has become empty. Useful in maintaining the vertices of a graph sorted by degree, which is a fundamental operation in graph algortihms. Still they are not as widely know as they should be. They are the right priority queue for any small, discrete range of keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Binary Search Trees__:\n",
    "    - Binary search trees make effective priority queues since the smallest element is always the leftmost leaf and the largest is always the rightmost leaf. The min/max is found by simply tracing down left/right pointer untill the next pointer is Nil. Binary tree heaps prove most appropriate when you need other dictionary operations, or if you have an unbounded key range and do not know the maximum priority queue size in advance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suffix Trees and Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chap12/02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A refrence string $ S $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a data structure to quickly find all places where an arbitrary query string $ q $ occur in $ S $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suffix trees and arrays are phenomenally useful data strucutres for solving string problems elegantly and efficently. Proper use of a suffix tree often speeds up string processing algorithms from $ O (n^2) $ to linear time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a suffix tree is simply a _trie_ of the $ n $ suffixes of an $ n$-character string $ S $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trie is a tree structure, where each edge represents one character and the root represents the null string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus each path from the root represents a string, described by the characters labeling the edges traversed. Any finite set of words defines a trie, and two words with common prefixes branch off from each other at the first distinguishing character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tries are useful for testing whether a given query string $ q $ is in the set. We traverse the trie from the root along branches defined by successive characters of $ q $. If a branch does not exist in the trie, then $ q $ cannot be in the set of strings. Otherwise we find $ q $ in $ | q | $ character comparisions regardles of how many strings are in the trie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tries are very simple to build (insering new strings) and very fast to search, although they can be expensive in terms of memeory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chap12/03.png)\n",
    "\n",
    "__Figure 12__: A trie on strings _the_ , _their_ , _there_ , _was_ and _when_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A suffix tree is simply a trie of all the proper suffixes of $ S $. The suffix tree enables you to test whether $ q $ is a substring of $ S $, because any substring of $ S $ is the prefix of some suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search time is again linear in the lenght of $ q $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The catch is that constructing a full suffix tree in this manner can require $ O(n^2)$ time and even worse $ O(n^2) $ space, since the average lenght of the $ n $ suffixes is $ n / 2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better, there exist O(n) algorithms to construct this collapsed tree, by making clever use of pointers to minimize construction time. These additional pointers can also be used to speed up many applications of suffix trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of Tries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Find all occurrences of q as a substring of $ S $__\n",
    "    - Jut as with a trie, we can walk from the root to the node $ n_q $. In collapsed suffix trees, it takes $ O(|q| + k) $ time to find the $ k $ occurences of $ q $ in $ S $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Longest substring common to a set of strings__:\n",
    "    - Build a single collapsed suffix tree containing all suffixes of all strings, with each leaf labeled with its orginal string. In the course of doing a depth-first search on this tree, we can label each node with both the lenght of its common prefix and the number of distinct strings that are children of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Find the longest palindrome in $ S $__:\n",
    "    - A _palindrome_ is a string that reads the same if the order of characters is reversed, such as _madam_. To find the longest palinfrome in a string $ S $, build a suffix tree containing all suffixes of $ S $ and the reversal of $ S $, with each leaf identified by its starting position. A palindrom is defined by any node in this tree that has forward and reversed children from same position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suffix Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suffix arrays do most of what suffix trees do, while using roughly four times less memory. They are also easier to implement. A suffix array is in principle just an array that contains all the $ n $ suffixes of $ S $ in sorted order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus a binary search of this array for string $ q $ suffices to locate the prefix of a sufix that matches $ q $, permitting an efficient substring search in $ O(lg n) $ string comparisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the addition of an index specifiying the common prefix lenght of all bounding suffixes, only $ lg n + |q| $ character comparisions needs be performed on any query, since we can identify the next character that must be tested in the binary search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing suffix arrays are difficult due to the $ O (n^2) $ characters in the strings beign sorted. One solution is to first build a suffix tree, then perform an in-order traversal of it to read the strings off in an sorted order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chap12/04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph $ G $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent the graph $ G $ using a felxible, efficent data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two basic data structures for represeting graphs are _adjacency matrices_ and _adjacency lists_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, for most things, adjacency lists are the way to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations/Descisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __How big will your graph be?__:\n",
    "    - How many vertices will it have, both typically and in the worst case? Ditto for the number of edges? Graphs with $ 1000 $ vertices imply adjacency matrices with $ 1,000,000 $ entries. This seems too be the boundary of reality. Adjaceny matrices make sense only for small or very dense graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __How dense will your graph be?__:\n",
    "    - If your graph is very dense, meaning that a large fraction of the vertex pairs define edges, there is a probably no compelling reason to use adjacency lists. You will be doomed to using $ Θ(n^2) $ space anyways. Indeed, for complete graphs, matrices will be more concise due to the elimination of pointers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Which algortihms will you be implementing?__:\n",
    "    - Certain algorithms are more natural on adjacency matrices (such as all-pairs shortest path) and other favor adjacency lists (such as most __DFS-based algortihms__. Adjacency matrices win for algorithms that repeatedly ask \"Is $(i, j) $ in  $ G $?\" Howerver, most graph algorithms can be designed to eliminate such queries\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Will you be modifiying the graph over the course of your application?__ \n",
    "    - Efficient static graph implementations can be used when no edges insertion/deleting operations will done following initial construction. Ineed more common than modifying the topology of the graph is modifying the attributes of a vertex or edge of the graph, such as size, wieght, label or color. Attributes are best handled as extra fields in the vertex or edge records of adjacency lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planer Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planer graphs are those that can be drawn in the plane so no two edges cross. Graphs arising in many applications are planer by definition, such as maps of countries. Others are planar by happenstance, like trees. Planar graphs are always sparse, since any $ n-$ vertex planer graph can have at most $ 3n - 6 $ edges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus they should be represented using adjacency lists. If the planar drawing (or embedding) of the graph is fundamental to what is being computed, planar graphs are the best represented geometrically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperGraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are generalized graphs where each edge may link subsets of more than two vertices. Suppose we want to represent who is on which congressional committee. The vertices of our hypergraph would be individual congressmen, while each hyperedge would represent one committee. Such arbitrary collections of subsets of a set are naturally though of as hypergraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two basic data structures for hypergraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incidence matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are analogous to adjacency matrices. They require $ n * m $ space, where $ m $ is the number of hyperedges. Each row corresponds to a vertex, and each column to an edge, with a nonzero entry in $ M[i, j]$ iff vertex $ i $ is incident to edge $ j $. On standard graphs there are two nonzero entries in each column. The degre of each vertex governs the number of nonzero entries in each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipartite Incidence Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are analogous to adjacency lists, and hence suited for sparse hypergraphs. There is a vertex of the incidence structure associated with each edge and vertex of the hypergraphs, and an edge $ (i, j) $ in the incidence structure if vertex $ i $ of the hypergraph appears in edge $ j $ of the hypergraph. Adjacency lists are typically used to represent this incidence structure. Drawing the associated bipartite graph provides an natural way to visualize the hypergraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Data Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chap12/05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A universe of items $ U = \\{u_1,..., u_n\\} $ on which is defined a collection of subsets $ S = \\{S_1,..., S_m\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent each subset so as to efficently $ (1) $ test whether $ u_i $ in $S_j$, $(2)$ compute the union or intersection of $ S_i $ and $ S_j $, and $ (3) $insert or delete members of $ S $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set is an unordered collection of objects drawn from a fixed universal set. Howerver, it is usually useful for implementation to represent each set in a single _cononical order_ , typically sorted, to speed up or simplify various operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted order truns the problem of finding the union or intersection of two subsets into a linear-time operation- just sweep from left to right and see what you are missing It makes possible element searching in sublinear time. Finally, printing the elements of a set in a cononical order paradoxically reminds us that order really doesnt matter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinquish sets from two other kinds of objects: dictionaries and strings. A collection of objects _not_ drawn from a fixed-size universal set is best though of as a _dictionary_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strings are structures where order matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Multisets_ permit elements to have more than one occurence. Data structures for sets can generall ybe extened to multisets by maintaining a count field or linked list equivalent entries for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation/Descisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Bit vectors__:\n",
    "    - An $n$-bit vector or array can represent any subsets $ S $ on a universal set $ U $ containing $ n $ items. Bit $ i $ will be $ 1 $ if $ i $ inE $ S $ and $ 0 $ if not. Since only one bit is needed per element, bit vectors can be very space efficient for surprisingly large values of $ | U | $. Element insertion and deletion simply flips the appropriate bit. \n",
    "    - Intersection and union are done by \"and-ing\" or \"or-ing\" the bits together. The only drawback of a bit vector is its performace on sparse subsets. For example, it takes $ O(n) $ time to explicitly identify all memebers of sparse (even empty) subset $ S $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Containers or dictionaries__\n",
    "    - A subset can also be represented using a linked list, array or dictionary containing exactly the elements in the subset. No notion of a fixed univerasal set is needed for such a data structure. For sparse subsets, dictionaries can be more space and time efficient than bit vectors and easier to work with and program. For efficient union and intersection operations, it pays to keep the elements in each subset sorted, so linear-time traversal through both subsets identifies all duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Boom Filters__:\n",
    "    - We can emulate a bit vector in the absence of a fixed universal set by hashing each subset element to an integer from $ 0 $ to $ n $ and setting the corresponding bit. Thus, bit $ H(e) $ will be $ 1 $ if $ e E S $. Collisions leave some possibility for error under this scheme, howerver, because a different key might have hashed to the same position \n",
    "    - Boom fileter use several (say k) different hash functions $ H_1, ..., H_k $, and set all $ k $ bits $ H_i(e)$ upon insertion of key $ e $. Now $ e $ is in $ S $ only if all $ k $ bits are $ 1 $. The probability of false positives xan be made arbitratily low by increasing the number of hash functions $ k $ and table size $ n $. With the proper constants, each subset element can be represented using a constant number of bits, independent of the size of the universal set. \n",
    "    - This hashing based data strucutre is much more space-efficent than dictionaries for static subset applications that can tolerate a small probability of error. Many can. For instance, a spell checker that left a rare random string undected would prove no great tragedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "many applications involve collections of subsets that are pairwise disjoint, meaning that each element is in exactly one subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vertex is in exactly one component. Such a system of subsets is called a _set partition_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problme with set partation data structures is maintaining changes over time. Perhaps as edges are added or party memebrs defect. Typical queries include \"which set is a particular item in?\" and \"are two items in the same set?\" as we modify the set by $ (1) $ changing one item, $ (2)$ merging or unioning two sets, or $( 3) $ breaking a set apart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Collection of containers__: representing each subset in its own container/dictionary permits fast access to all the elements in the subset, which facilitates union and intersection operations. The cost comes in membership testing, as we must search each subset data structure independently until we find our target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Generalized bit vector__: Let the $ ith $ element of an array denote the number/name of the subset that contains it. Set identification queries and single elements modifications can be performed in constant time. Howerver operations like performing the union of two subsets take time proportional to the size of the universe, since each element in the two subsets must be identifies and (at least one subset's worth) must have its name changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dictionaries with a subset attribute__: Similarly, each item in a binary tree can be associated a field that records the name of the subset it is in. Set identification queries and single element modifications c an be performed in the time it takes to search in the dictionary. Howerver, union/intersection operatios are again slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Union-find data structure: we represent a subset using a rooted tree where each node points to its parent instead of its children. The naame of each subset will be the name of the item at the root. Finding out which subset we are in is simple, for we keep traversing up the parent pointers untill we hit the root. Unioning two subsets is also easy. Just assign the root of one of two trees to point to the other, so now all elements have the same root and hence the same subset name\n",
    "- Implementation details have a big impact on asympototic performance. Always selecting the larger (or taller) tree as the root in a merger guarantees logarithmic hegiht trees. Retraversing the path traced on each find and explicitrly pointing all nodes on the path to the root (path compression) reduces the tree to almost constant height. Union find is a fast, simple data strucutre every programmer should know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kd-Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/chap12/06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set $ S $ of $ n $ points or more complicated geometric objects in $ k $ dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tree that partitions space by half-places such that each object is contaned in its own box-shaped region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kd-tree and related spacial data structures hierarchically decompose space into small number of cells, each containing a few representives from an input set of point ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a fast way to access any object by position. We traverse down the hierachy untill we find the smallest cell containing it, and then scan through the object in the cell to identify the right one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical algorithms constuct __kd-Trees__ by partitioning point sets. Each node in the tree is defined by a plane cutting through one of the dimensions. Ideally, this plane equally partitions the subset of points into left/right (or up/down) subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These children are again partitioned into equal halves, using planes through a different dimesnsion. Partitioning stops after $ lg n $ levels, with each point in its own leaf cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cutting planes along any path from the root to another node defines a unique box-shaped region of space. Each subsequent plane cuts this box into two boxes. Each box-shaped region is defined by $ 2k $ planes, where $ k $ is the number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed the $ kd $ in kd-tree is short for $k$-dimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maintain the region of intrest defined by the intersection of these half-spaces as we move up the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flavors of $ kd $ trees differ in exactly how the splitting plane is selected. Options include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Clycling though the dimensions__ -partionion first on $ d_1 $ then $ d_2, ..., d_k $ before cycling back to $ d_1 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Cutting along the largest dimension__ -select the partion dimension to make the resulting boxes as squares or cube-like as possible. Selecting a plane to partition the points in half does not mean selecting a splitter in the middle of the box-shaped regions, since all the points may lie in the left side of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Quadtrees or Octtree__ - Instead of partitiong with single planes, use all axis-parallel planes that pass through a given partition point. In two dimensions, this means creating four child cells; in 3D, it means eight child cells. Quadtrees seem particulary popular on image data, where leaf cells imply that all pixels in the regions have the same color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __BSP Trees__: - Binary space partions use general (i.e., not just axis-parallel cutting planes to carve up space into cells so that each cell ends up containing only one object (say a polygon). Such partitions are not possible using only axis-parallel cuts for certain sets of objects. The downside is that such polyhedral cell boundaries are more complicated to work with than boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __R-trees__ -This is another spatial data structure useful for geometic objects that cannot be parititoned into axis-oriented boxed without cutting them into pieces. At each level, the objects are partitioned into a smaller number of (possibly-overlapping) boxes to construct searchable hierarchies without partitioning objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideall the partitions split both the space (ensuring fat, regular regions) and the set points (ensuring a log height tree) evenly, but doing both simultaneously can be impossible on a given input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of fat cells become clear in many applications of kd-trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Point location__ -to identify which cell a query point $ q $ lie in, we start at the root and test which side of the parition plane contains $ q $. Bt repeating the process on the appropriate child node, we travel down the tree to find the leaf cell containing $ q $ in time proprotinal to its height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Nearest neighbor search__ - to find the point in $ S $ to a query point $ q $, we perform point location to find the cell $ c $ contains $ q $. Since $ c $ is borderred by some point $ p $, we can compute the distance $ d(p, q) $ from $ p $ to $ q $. Point $ p $ is likely close to $ q $, but it might not be the single closest neighbor might lie just to the left of the boundary in another cell. Thus, we must travel all cells that lie within a distance of $ d(p, q) $ of cell $ c $ and verify that none of them contain closer points. In trees, with nice fat cells, very few cells should need to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Range Search__ - Which points lie within a query box or region? Starting from the root, check whether the query region intersects (or contains) the cell defining the current node. If it does, check the children; if not, none of the leaf cells below this node can possibly be of intrest. We quickly prune away irrelevant portions of the space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Partial key search__ - SUppose we want to find a point $ p $ in $ S $, but we do not have full information about $ p $. Say we are looking for someone of age $ 35 $ and height $ 5'8 $ but of unknown weight in a $ 3D-tree$ with dimensions of age, weight and height. Starting from the root, we can identify the correct descendant for all but the weight dimension. To be sure we find the right point, we must search both children of these nodes. The more fields we know the better, but such partial key search can be substantially faster than checking all points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ kd $ trees are most useful for a small to moderate number of dimensions, say from $ 2 $ up to maybe $ 20 $ dimensions. They lose effectiveness because the ratio of the volume of a unit sphere in $ k $ dimensions shirnks exponentially compared to the unit cube"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
